import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import base64
import io
import time
import threading
import queue
from subprocess import Popen, PIPE, STDOUT
import re
import html
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from bs4 import BeautifulSoup

# ë°ì´í„° êµ¬ì¡° ì •ì˜
@dataclass
class RoadmapChunk:
    id: str
    roadmap_id: str
    content: str
    html_fragment: str
    embedding: List[float]
    chunk_index: int
    metadata: Dict[str, Any]
    collection_tags: List[str]  # ìˆ˜ì§‘ì„ ìœ„í•œ íƒœê·¸ (ì¹´í…Œê³ ë¦¬, íƒ€ì…, ë‚œì´ë„ ë“±)
    search_tags: List[str]      # ê²€ìƒ‰ì„ ìœ„í•œ íƒœê·¸ (í‚¤ì›Œë“œ, ê¸°ìˆ  ìŠ¤íƒ ë“±)

@dataclass
class RoadmapDocument:
    id: str
    title: str
    original_html: str
    chunks: List[RoadmapChunk]
    metadata: Dict[str, Any]

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ—ºï¸ í•™ìŠµë¡œë“œë§µ ì‹œìŠ¤í…œ",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
        color: white;
        padding: 2rem;
        border-radius: 0.5rem;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        padding: 1.5rem;
        border-radius: 0.5rem;
        border: 2px solid #cbd5e1;
        margin-bottom: 1rem;
    }
    
    .status-success {
        background: #dcfce7;
        color: #166534;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }
    
    .status-pending {
        background: #fef3c7;
        color: #92400e;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }
    
    .status-error {
        background: #fee2e2;
        color: #991b1b;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }
    
    .upload-box {
        border: 2px dashed #f59e0b;
        border-radius: 0.5rem;
        padding: 2rem;
        text-align: center;
        background: #fef3c7;
        margin: 1rem 0;
    }
    
    .chunk-preview {
        background: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.375rem;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    .similarity-score {
        background: #e3f2fd;
        color: #1976d2;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-size: 0.875rem;
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'roadmaps' not in st.session_state:
    st.session_state.roadmaps = []
if 'logs' not in st.session_state:
    st.session_state.logs = [
        {"ë‚ ì§œ": "2024-01-15 14:30", "ë³€ê²½ë‚´ìš©": "React ë¡œë“œë§µ ë³´ì™„", "ìƒíƒœ": "ì™„ë£Œ"},
        {"ë‚ ì§œ": "2024-01-15 13:45", "ë³€ê²½ë‚´ìš©": "Python ë§í¬ ê²€ì¦", "ìƒíƒœ": "ì§„í–‰ì¤‘"},
        {"ë‚ ì§œ": "2024-01-15 12:20", "ë³€ê²½ë‚´ìš©": "JavaScript ë…¸ë“œ ì¶”ê°€", "ìƒíƒœ": "ì‹¤íŒ¨"}
    ]
if 'validation_progress' not in st.session_state:
    st.session_state.validation_progress = 0
if 'uploaded_filenames' not in st.session_state:
    st.session_state.uploaded_filenames = []
if 'roadmap_documents' not in st.session_state:
    st.session_state.roadmap_documents = {}
if 'custom_tags' not in st.session_state:
    st.session_state.custom_tags = {}
if 'tag_suggestions' not in st.session_state:
    st.session_state.tag_suggestions = [
        "frontend", "backend", "database", "devops", "mobile", "ai", "ml", "data-science",
        "web-development", "mobile-development", "game-development", "security", "testing",
        "react", "vue", "angular", "nodejs", "python", "java", "javascript", "typescript",
        "html", "css", "sql", "mongodb", "postgresql", "docker", "kubernetes", "aws",
        "azure", "gcp", "git", "github", "ci-cd", "agile", "scrum", "ui-ux", "api",
        "microservices", "serverless", "blockchain", "iot", "cloud-computing"
    ]

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def extract_keywords(content: str) -> List[str]:
    """ì»¨í…ì¸ ì—ì„œ ê¸°ìˆ  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    tech_keywords = re.findall(r'\b(JavaScript|Python|React|Node\.js|HTML|CSS|API|Database|TypeScript|Vue|Angular|Django|Flask|Express|MongoDB|PostgreSQL|MySQL|Git|Docker|AWS|Azure|GCP)\b', content, re.IGNORECASE)
    return list(set([kw.lower() for kw in tech_keywords]))

def extract_roadmap_metadata(html_content: str) -> Dict[str, Any]:
    """HTMLì—ì„œ ë¡œë“œë§µ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    metadata = {
        "category": "programming",
        "difficulty": "intermediate",
        "tags": [],
        "created_at": datetime.now().isoformat()
    }
    
    # ì œëª© ì¶”ì¶œ
    title_match = re.search(r'<title[^>]*>(.*?)</title>', html_content, re.IGNORECASE)
    if title_match:
        metadata["title"] = title_match.group(1).strip()
    
    # íƒœê·¸ ì¶”ì¶œ
    tags = extract_keywords(html_content)
    metadata["tags"] = tags[:10]  # ìƒìœ„ 10ê°œë§Œ
    
    # ë‚œì´ë„ ì¶”ì¶œ
    if any(word in html_content.lower() for word in ["beginner", "ê¸°ì´ˆ", "ì…ë¬¸"]):
        metadata["difficulty"] = "beginner"
    elif any(word in html_content.lower() for word in ["advanced", "ê³ ê¸‰", "ì‹¬í™”"]):
        metadata["difficulty"] = "advanced"
    
    return metadata

def parse_html_sections(html_content: str, roadmap_id: str) -> List[RoadmapChunk]:
    """HTMLì„ ì˜ë¯¸ìˆëŠ” ì„¹ì…˜ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì²­í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    chunks = []
    
    try:
        # ê³„ì¸µ êµ¬ì¡° íŒŒì‹± (ë ˆë²¨ > ë¸Œëœì¹˜ > ì„œë¸Œë¸Œëœì¹˜)
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ë©”ì¸ ë¸Œëœì¹˜ë“¤ ì°¾ê¸° (ë‹¤ì–‘í•œ íŒ¨í„´ ì‹œë„)
        main_branches = None
        
        # íŒ¨í„´ 1: main-branches í´ë˜ìŠ¤
        main_branches = soup.find('div', class_='main-branches')
        
        # íŒ¨í„´ 2: branch, level, mainì´ í¬í•¨ëœ í´ë˜ìŠ¤
        if not main_branches:
            main_branches = soup.find_all(['section', 'div'], class_=re.compile(r'branch|level|main'))
        
        # íŒ¨í„´ 3: íŠ¹ì • êµ¬ì¡° ì°¾ê¸°
        if not main_branches:
            # h1, h2, h3 íƒœê·¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì¡° ì°¾ê¸°
            headings = soup.find_all(['h1', 'h2', 'h3'])
            if headings:
                main_branches = []
                for heading in headings:
                    # í—¤ë”© ë‹¤ìŒì˜ divë‚˜ sectionì„ ì°¾ê¸°
                    next_sibling = heading.find_next_sibling(['div', 'section'])
                    if next_sibling:
                        main_branches.append(next_sibling)
        
        # íŒ¨í„´ 4: ëª¨ë“  divë¥¼ ë¸Œëœì¹˜ë¡œ ê°„ì£¼
        if not main_branches:
            main_branches = soup.find_all('div', class_=True)
        
        if main_branches:
            # êµ¬ì¡°í™”ëœ íŒŒì‹±
            chunks = _parse_structured_content(roadmap_id, main_branches, soup)
        else:
            # ê¸°ë³¸ ì„¹ì…˜ë³„ ë¶„í• 
            chunks = _parse_basic_sections(roadmap_id, html_content)
        
        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì²­í¬ë¼ë„ ìƒì„±ë˜ë„ë¡ ë³´ì¥
        if not chunks:
            chunks = _create_fallback_chunk(roadmap_id, html_content)
        
    except Exception as e:
        st.error(f"íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì²­í¬ ìƒì„±
        chunks = _create_fallback_chunk(roadmap_id, html_content)
    
    return chunks

def _parse_structured_content(roadmap_id: str, main_branches, soup) -> List[RoadmapChunk]:
    """êµ¬ì¡°í™”ëœ ì½˜í…ì¸  íŒŒì‹±"""
    chunks = []
    chunk_index = 0
    
    try:
        # ì œëª© ì¶”ì¶œ
        title_elem = soup.find(['h1', 'title'])
        main_title = title_elem.get_text().strip() if title_elem else "í•™ìŠµ ë¡œë“œë§µ"
        
        # ë ˆë²¨ë³„ íŒŒì‹±
        for level_idx, level_branch in enumerate(main_branches):
            try:
                # ë ˆë²¨ ë…¸ë“œ ì°¾ê¸° (ë‹¤ì–‘í•œ íŒ¨í„´ ì‹œë„)
                level_node = None
                
                # íŒ¨í„´ 1: level, branch í´ë˜ìŠ¤
                level_node = level_branch.find(['div', 'h2'], class_=re.compile(r'level|branch'))
                
                # íŒ¨í„´ 2: ì²« ë²ˆì§¸ divë‚˜ h2
                if not level_node:
                    level_node = level_branch.find(['div', 'h2'])
                
                # íŒ¨í„´ 3: level_branch ìì²´ë¥¼ ì‚¬ìš©
                if not level_node:
                    level_node = level_branch
                
                if level_node:
                    level_title = level_node.get_text().strip()
                    if not level_title:
                        level_title = f"ë ˆë²¨ {level_idx + 1}"
                    
                    level_category = _extract_category_from_classes(level_node.get('class', []))
                    
                    # ë ˆë²¨ ì²­í¬ ìƒì„±
                    level_chunk = RoadmapChunk(
                        id=f"{roadmap_id}_level_{level_idx}",
                        roadmap_id=roadmap_id,
                        content=f"{level_title} - {level_category} ë‹¨ê³„",
                        html_fragment=str(level_branch),
                        embedding=[],
                        chunk_index=chunk_index,
                        metadata={
                            "section": level_title,
                            "level": level_idx + 1,
                            "category": level_category,
                            "type": "level",
                            "keywords": extract_keywords(level_title),
                            "tools": _extract_tools(level_branch),
                            "resources": _extract_resources(level_branch),
                            "learning_objectives": _extract_learning_objectives(level_branch)
                        },
                        collection_tags=[f"level-{level_category}"],
                        search_tags=[f"level-{level_category}"]
                    )
                    chunks.append(level_chunk)
                    chunk_index += 1
                    
                    # ë¸Œëœì¹˜ íŒŒì‹± (ë‹¤ì–‘í•œ íŒ¨í„´ ì‹œë„)
                    branches = []
                    
                    # íŒ¨í„´ 1: branch, sub í´ë˜ìŠ¤
                    branches = level_branch.find_all(['div'], class_=re.compile(r'branch|sub'))
                    
                    # íŒ¨í„´ 2: ëª¨ë“  div
                    if not branches:
                        branches = level_branch.find_all('div')
                    
                    # íŒ¨í„´ 3: ëª¨ë“  ìì‹ ìš”ì†Œ
                    if not branches:
                        branches = level_branch.find_all(['div', 'section', 'p'])
                    
                    for branch_idx, branch in enumerate(branches):
                        try:
                            branch_title = branch.get_text().strip()
                            if not branch_title:
                                branch_title = f"ë¸Œëœì¹˜ {branch_idx + 1}"
                            
                            # ë„ˆë¬´ ì§§ì€ ë‚´ìš©ì€ ê±´ë„ˆë›°ê¸°
                            if len(branch_title) < 3:
                                continue
                            
                            branch_chunk = RoadmapChunk(
                                id=f"{roadmap_id}_branch_{level_idx}_{branch_idx}",
                                roadmap_id=roadmap_id,
                                content=branch_title,
                                html_fragment=str(branch),
                                embedding=[],
                                chunk_index=chunk_index,
                                metadata={
                                    "section": branch_title,
                                    "level": level_idx + 1,
                                    "branch": branch_idx + 1,
                                    "category": level_category,
                                    "type": "branch",
                                    "keywords": extract_keywords(branch_title),
                                    "tools": _extract_tools(branch),
                                    "resources": _extract_resources(branch),
                                    "learning_objectives": _extract_learning_objectives(branch)
                                },
                                collection_tags=[f"branch-{branch_title}"],
                                search_tags=[f"branch-{branch_title}"]
                            )
                            chunks.append(branch_chunk)
                            chunk_index += 1
                            
                            # ì„œë¸Œë¸Œëœì¹˜ íŒŒì‹± (ì„ íƒì )
                            sub_branches = branch.find_all(['div'], class_=re.compile(r'sub|detail'))
                            if not sub_branches:
                                sub_branches = branch.find_all(['div', 'p'])
                            
                            for sub_idx, sub_branch in enumerate(sub_branches[:3]):  # ìµœëŒ€ 3ê°œë§Œ
                                try:
                                    sub_title = sub_branch.get_text().strip()
                                    if not sub_title or len(sub_title) < 3:
                                        continue
                                    
                                    sub_chunk = RoadmapChunk(
                                        id=f"{roadmap_id}_sub_{level_idx}_{branch_idx}_{sub_idx}",
                                        roadmap_id=roadmap_id,
                                        content=sub_title,
                                        html_fragment=str(sub_branch),
                                        embedding=[],
                                        chunk_index=chunk_index,
                                        metadata={
                                            "section": sub_title,
                                            "level": level_idx + 1,
                                            "branch": branch_idx + 1,
                                            "sub": sub_idx + 1,
                                            "category": level_category,
                                            "type": "sub_branch",
                                            "keywords": extract_keywords(sub_title),
                                            "tools": _extract_tools(sub_branch),
                                            "resources": _extract_resources(sub_branch),
                                            "learning_objectives": _extract_learning_objectives(sub_branch)
                                        },
                                        collection_tags=[f"sub-branch-{sub_title}"],
                                        search_tags=[f"sub-branch-{sub_title}"]
                                    )
                                    chunks.append(sub_chunk)
                                    chunk_index += 1
                                except Exception as e:
                                    st.warning(f"ì„œë¸Œë¸Œëœì¹˜ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                                    continue
                                    
                        except Exception as e:
                            st.warning(f"ë¸Œëœì¹˜ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                            continue
                            
            except Exception as e:
                st.warning(f"ë ˆë²¨ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì²­í¬ë¼ë„ ìƒì„±ë˜ë„ë¡ ë³´ì¥
        if not chunks:
            # ì „ì²´ HTMLì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìƒì„±
            fallback_chunk = RoadmapChunk(
                id=f"{roadmap_id}_fallback_structured",
                roadmap_id=roadmap_id,
                content=main_title,
                html_fragment=str(soup),
                embedding=[],
                chunk_index=0,
                metadata={
                    "section": main_title,
                    "level": 1,
                    "category": "unknown",
                    "type": "fallback_structured",
                    "keywords": extract_keywords(main_title),
                    "tools": [],
                    "resources": [],
                    "learning_objectives": []
                },
                collection_tags=["unknown"],
                search_tags=["unknown"]
            )
            chunks.append(fallback_chunk)
            
    except Exception as e:
        st.error(f"êµ¬ì¡°í™”ëœ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì²­í¬ ìƒì„±
        fallback_chunk = RoadmapChunk(
            id=f"{roadmap_id}_error_fallback",
            roadmap_id=roadmap_id,
            content="íŒŒì‹± ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì²­í¬",
            html_fragment="",
            embedding=[],
            chunk_index=0,
            metadata={
                "section": "ì˜¤ë¥˜",
                "level": 1,
                "category": "error",
                "type": "error",
                "keywords": [],
                "tools": [],
                "resources": [],
                "learning_objectives": []
            },
            collection_tags=["error"],
            search_tags=["error"]
        )
        chunks.append(fallback_chunk)
    
    return chunks

def _parse_basic_sections(roadmap_id: str, html_content: str) -> List[RoadmapChunk]:
    """ê¸°ë³¸ ì„¹ì…˜ë³„ ë¶„í• """
    chunks = []
    
    # ì„¹ì…˜ë³„ë¡œ ë¶„í•  (section, .step, .module, h2, h3 íƒœê·¸ ê¸°ì¤€)
    section_patterns = [
        r'<section[^>]*>(.*?)</section>',
        r'<div[^>]*class="[^"]*step[^"]*"[^>]*>(.*?)</div>',
        r'<div[^>]*class="[^"]*module[^"]*"[^>]*>(.*?)</div>',
        r'<h2[^>]*>(.*?)</h2>',
        r'<h3[^>]*>(.*?)</h3>',
        r'<div[^>]*class="[^"]*"[^>]*>(.*?)</div>',  # ëª¨ë“  div
        r'<p[^>]*>(.*?)</p>'  # ëª¨ë“  p íƒœê·¸
    ]
    
    all_sections = []
    for pattern in section_patterns:
        sections = re.findall(pattern, html_content, re.DOTALL | re.IGNORECASE)
        all_sections.extend(sections)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    unique_sections = []
    for section in all_sections:
        cleaned = re.sub(r'<[^>]+>', '', section).strip()
        if cleaned and len(cleaned) > 5:  # ìµœì†Œ ê¸¸ì´ ì¡°ê±´ ì™„í™”
            unique_sections.append((section, cleaned))
    
    # ê¸°ë³¸ ì²­í¬ ìƒì„±
    for i, (html_fragment, content) in enumerate(unique_sections):
        chunk = _create_basic_chunk(roadmap_id, i, html_fragment, content)
        chunks.append(chunk)
    
    return chunks

def _create_fallback_chunk(roadmap_id: str, html_content: str) -> List[RoadmapChunk]:
    """íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²­í¬ ìƒì„±"""
    # HTMLì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    soup = BeautifulSoup(html_content, 'html.parser')
    text_content = soup.get_text().strip()
    
    if not text_content:
        text_content = "íŒŒì‹±í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì œëª© ì¶”ì¶œ ì‹œë„
    title_elem = soup.find(['h1', 'title'])
    title = title_elem.get_text().strip() if title_elem else "í•™ìŠµ ë¡œë“œë§µ"
    
    chunk = RoadmapChunk(
        id=f"{roadmap_id}_fallback",
        roadmap_id=roadmap_id,
        content=text_content[:500] + "..." if len(text_content) > 500 else text_content,
        html_fragment=html_content[:1000] + "..." if len(html_content) > 1000 else html_content,
        embedding=[],
        chunk_index=0,
        metadata={
            "section": title,
            "step_number": 1,
            "type": "fallback",
            "level": 1,
            "category": "unknown",
            "keywords": extract_keywords(text_content),
            "tools": _extract_tools_from_text(text_content),
            "resources": _extract_resources_from_text(text_content),
            "learning_objectives": _extract_learning_objectives_from_text(text_content)
        },
        collection_tags=["unknown"],
        search_tags=["unknown"]
    )
    
    return [chunk]

def _create_basic_chunk(roadmap_id: str, index: int, html_fragment: str, content: str) -> RoadmapChunk:
    """ê¸°ë³¸ ì²­í¬ ìƒì„±"""
    # ì„¹ì…˜ ì œëª© ì¶”ì¶œ
    title_match = re.search(r'<h[1-6][^>]*>(.*?)</h[1-6]>', html_fragment, re.IGNORECASE)
    section_title = title_match.group(1).strip() if title_match else f"ì„¹ì…˜ {index+1}"
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(content)
    
    return RoadmapChunk(
        id=f"{roadmap_id}_chunk_{index}",
        roadmap_id=roadmap_id,
        content=content,
        html_fragment=html_fragment,
        embedding=[],
        chunk_index=index,
        metadata={
            "section": section_title,
            "step_number": index + 1,
            "keywords": keywords,
            "tools": _extract_tools_from_text(content),
            "resources": _extract_resources_from_text(content),
            "learning_objectives": _extract_learning_objectives_from_text(content)
        },
        collection_tags=["unknown"],
        search_tags=["unknown"]
    )

def _extract_category_from_classes(classes: List[str]) -> str:
    """í´ë˜ìŠ¤ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
    class_str = ' '.join(classes).lower()
    if 'beginner' in class_str or 'ê¸°ì´ˆ' in class_str:
        return 'beginner'
    elif 'advanced' in class_str or 'ê³ ê¸‰' in class_str:
        return 'advanced'
    elif 'intermediate' in class_str or 'ì¤‘ê¸‰' in class_str:
        return 'intermediate'
    else:
        return 'community'

def _extract_tools(element) -> List[str]:
    """ìš”ì†Œì—ì„œ ë„êµ¬ ì¶”ì¶œ"""
    tools = []
    text = element.get_text().lower()
    
    # ë„êµ¬ í‚¤ì›Œë“œ íŒ¨í„´
    tool_patterns = [
        r'\b(vscode|visual studio|sublime|atom|webstorm|intellij)\b',
        r'\b(git|github|gitlab|bitbucket)\b',
        r'\b(docker|kubernetes|jenkins|travis)\b',
        r'\b(npm|yarn|webpack|vite|parcel)\b',
        r'\b(react|vue|angular|svelte)\b',
        r'\b(node\.js|express|django|flask|spring)\b'
    ]
    
    for pattern in tool_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        tools.extend(matches)
    
    return list(set(tools))

def _extract_resources(element) -> List[Dict[str, str]]:
    """ìš”ì†Œì—ì„œ ë¦¬ì†ŒìŠ¤ ì¶”ì¶œ"""
    resources = []
    
    # ë§í¬ ì°¾ê¸°
    links = element.find_all('a', href=True)
    for link in links:
        url = link.get('href', '')
        title = link.get_text().strip()
        if url and title:
            resources.append({
                'url': url,
                'title': title,
                'type': _determine_resource_type(url)
            })
    
    return resources

def _extract_learning_objectives(element) -> List[str]:
    """ìš”ì†Œì—ì„œ í•™ìŠµ ëª©í‘œ ì¶”ì¶œ"""
    objectives = []
    text = element.get_text()
    
    # í•™ìŠµ ëª©í‘œ íŒ¨í„´
    objective_patterns = [
        r'í•™ìŠµ\s*ëª©í‘œ[:\s]*([^.]*)',
        r'ëª©í‘œ[:\s]*([^.]*)',
        r'ì´í•´\s*í• \s*ìˆ˜\s*ìˆ[ì–´ì•¼]*\s*í•œë‹¤?[:\s]*([^.]*)',
        r'í• \s*ìˆ˜\s*ìˆ[ì–´ì•¼]*\s*í•œë‹¤?[:\s]*([^.]*)'
    ]
    
    for pattern in objective_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        objectives.extend(matches)
    
    return objectives

def _extract_tools_from_text(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë„êµ¬ ì¶”ì¶œ"""
    return _extract_tools_from_text_helper(text)

def _extract_resources_from_text(text: str) -> List[Dict[str, str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë¦¬ì†ŒìŠ¤ ì¶”ì¶œ"""
    resources = []
    
    # URL íŒ¨í„´ ì°¾ê¸°
    url_pattern = r'https?://[^\s<>"]+'
    urls = re.findall(url_pattern, text)
    
    for url in urls:
        resources.append({
            'url': url,
            'title': f"ë¦¬ì†ŒìŠ¤ {len(resources) + 1}",
            'type': _determine_resource_type(url)
        })
    
    return resources

def _extract_learning_objectives_from_text(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ í•™ìŠµ ëª©í‘œ ì¶”ì¶œ"""
    return _extract_learning_objectives_from_text_helper(text)

def _extract_tools_from_text_helper(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë„êµ¬ ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜"""
    tools = []
    text_lower = text.lower()
    
    tool_patterns = [
        r'\b(vscode|visual studio|sublime|atom|webstorm|intellij)\b',
        r'\b(git|github|gitlab|bitbucket)\b',
        r'\b(docker|kubernetes|jenkins|travis)\b',
        r'\b(npm|yarn|webpack|vite|parcel)\b',
        r'\b(react|vue|angular|svelte)\b',
        r'\b(node\.js|express|django|flask|spring)\b'
    ]
    
    for pattern in tool_patterns:
        matches = re.findall(pattern, text_lower, re.IGNORECASE)
        tools.extend(matches)
    
    return list(set(tools))

def _extract_learning_objectives_from_text_helper(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ í•™ìŠµ ëª©í‘œ ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜"""
    objectives = []
    
    objective_patterns = [
        r'í•™ìŠµ\s*ëª©í‘œ[:\s]*([^.]*)',
        r'ëª©í‘œ[:\s]*([^.]*)',
        r'ì´í•´\s*í• \s*ìˆ˜\s*ìˆ[ì–´ì•¼]*\s*í•œë‹¤?[:\s]*([^.]*)',
        r'í• \s*ìˆ˜\s*ìˆ[ì–´ì•¼]*\s*í•œë‹¤?[:\s]*([^.]*)'
    ]
    
    for pattern in objective_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        objectives.extend(matches)
    
    return objectives

def _determine_resource_type(url: str) -> str:
    """URLì—ì„œ ë¦¬ì†ŒìŠ¤ íƒ€ì… ê²°ì •"""
    url_lower = url.lower()
    if any(ext in url_lower for ext in ['.pdf', '.doc', '.docx']):
        return 'document'
    elif any(ext in url_lower for ext in ['.mp4', '.avi', '.mov', 'youtube.com', 'vimeo.com']):
        return 'video'
    elif any(ext in url_lower for ext in ['.jpg', '.png', '.gif']):
        return 'image'
    elif 'github.com' in url_lower:
        return 'code'
    elif any(domain in url_lower for domain in ['stackoverflow.com', 'docs.', 'tutorial']):
        return 'tutorial'
    else:
        return 'link'

def suggest_tags_for_chunk(chunk_content: str, chunk_metadata: Dict[str, Any]) -> Dict[str, List[str]]:
    """ì²­í¬ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘ íƒœê·¸ì™€ ê²€ìƒ‰ íƒœê·¸ ì œì•ˆ"""
    collection_tags = []
    search_tags = []
    
    # ê¸°ì¡´ í‚¤ì›Œë“œì—ì„œ íƒœê·¸ ì¶”ì¶œ
    keywords = chunk_metadata.get("keywords", [])
    for keyword in keywords:
        if keyword.lower() in st.session_state.tag_suggestions:
            search_tags.append(keyword.lower())
    
    # ë„êµ¬ì—ì„œ íƒœê·¸ ì¶”ì¶œ
    tools = chunk_metadata.get("tools", [])
    for tool in tools:
        tool_lower = tool.lower()
        if tool_lower in st.session_state.tag_suggestions:
            search_tags.append(tool_lower)
    
    # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ìˆ˜ì§‘ íƒœê·¸
    category = chunk_metadata.get("category", "").lower()
    if category in ["beginner", "intermediate", "advanced"]:
        collection_tags.append(f"level-{category}")
        collection_tags.append(f"difficulty-{category}")
    
    # íƒ€ì… ê¸°ë°˜ ìˆ˜ì§‘ íƒœê·¸
    chunk_type = chunk_metadata.get("type", "").lower()
    if chunk_type in ["level", "branch", "sub_branch"]:
        collection_tags.append(f"type-{chunk_type}")
        collection_tags.append(f"structure-{chunk_type}")
    
    # ë ˆë²¨ ê¸°ë°˜ ìˆ˜ì§‘ íƒœê·¸
    level = chunk_metadata.get("level", "")
    if level:
        collection_tags.append(f"hierarchy-level-{level}")
    
    # ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰ íƒœê·¸ ì¶”ì¶œ
    content_lower = chunk_content.lower()
    
    # ê¸°ìˆ  ìŠ¤íƒ ê²€ìƒ‰ íƒœê·¸
    tech_patterns = {
        "frontend": ["react", "vue", "angular", "html", "css", "javascript", "typescript"],
        "backend": ["nodejs", "python", "java", "php", "ruby", "go"],
        "database": ["sql", "mongodb", "postgresql", "mysql", "redis"],
        "devops": ["docker", "kubernetes", "jenkins", "git", "aws", "azure"],
        "mobile": ["react-native", "flutter", "ios", "android", "swift", "kotlin"],
        "ai": ["machine-learning", "deep-learning", "tensorflow", "pytorch", "scikit-learn"],
        "security": ["authentication", "authorization", "encryption", "ssl", "oauth"],
        "testing": ["unit-test", "integration-test", "e2e-test", "jest", "cypress"]
    }
    
    for tag, patterns in tech_patterns.items():
        if any(pattern in content_lower for pattern in patterns):
            search_tags.append(tag)
    
    # ë„ë©”ì¸ë³„ ìˆ˜ì§‘ íƒœê·¸
    domain_patterns = {
        "web-development": ["web", "website", "frontend", "backend"],
        "mobile-development": ["mobile", "app", "ios", "android"],
        "data-science": ["data", "analysis", "statistics", "machine-learning"],
        "game-development": ["game", "unity", "unreal", "gaming"],
        "cybersecurity": ["security", "hacking", "penetration", "vulnerability"]
    }
    
    for domain, patterns in domain_patterns.items():
        if any(pattern in content_lower for pattern in patterns):
            collection_tags.append(domain)
    
    return {
        "collection_tags": list(set(collection_tags)),
        "search_tags": list(set(search_tags))
    }

def apply_tags_to_chunk(chunk: RoadmapChunk, custom_collection_tags: List[str] = None, custom_search_tags: List[str] = None) -> RoadmapChunk:
    """ì²­í¬ì— ì»¤ìŠ¤í…€ íƒœê·¸ë¥¼ ì ìš©"""
    # ê¸°ì¡´ íƒœê·¸ì™€ ìƒˆ íƒœê·¸ ê²°í•©
    updated_collection_tags = chunk.collection_tags.copy()
    updated_search_tags = chunk.search_tags.copy()
    
    if custom_collection_tags:
        updated_collection_tags.extend(custom_collection_tags)
        updated_collection_tags = list(set(updated_collection_tags))
    
    if custom_search_tags:
        updated_search_tags.extend(custom_search_tags)
        updated_search_tags = list(set(updated_search_tags))
    
    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ê¸°ì¡´ í‚¤ì›Œë“œë„ ìœ ì§€)
    updated_metadata = chunk.metadata.copy()
    if custom_search_tags:
        existing_keywords = updated_metadata.get("keywords", [])
        updated_metadata["keywords"] = list(set(existing_keywords + custom_search_tags))
    
    # ìƒˆë¡œìš´ ì²­í¬ ê°ì²´ ìƒì„±
    return RoadmapChunk(
        id=chunk.id,
        roadmap_id=chunk.roadmap_id,
        content=chunk.content,
        html_fragment=chunk.html_fragment,
        embedding=chunk.embedding,
        chunk_index=chunk.chunk_index,
        metadata=updated_metadata,
        collection_tags=updated_collection_tags,
        search_tags=updated_search_tags
    )

def search_chunks_by_tags(chunks: List[RoadmapChunk], search_tags: List[str], tag_type: str = "search") -> List[RoadmapChunk]:
    """íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ì²­í¬ ê²€ìƒ‰ (ìˆ˜ì§‘ íƒœê·¸ ë˜ëŠ” ê²€ìƒ‰ íƒœê·¸ ì„ íƒ ê°€ëŠ¥)"""
    if not search_tags:
        return chunks
    
    matched_chunks = []
    for chunk in chunks:
        if tag_type == "collection":
            chunk_tags = chunk.collection_tags
        else:  # search
            chunk_tags = chunk.search_tags
        
        # í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ í¬í•¨
        if any(tag.lower() in [ct.lower() for ct in chunk_tags] for tag in search_tags):
            matched_chunks.append(chunk)
    
    return matched_chunks

def get_tag_statistics(chunks: List[RoadmapChunk]) -> Dict[str, Dict[str, int]]:
    """ì²­í¬ë“¤ì˜ ìˆ˜ì§‘ íƒœê·¸ì™€ ê²€ìƒ‰ íƒœê·¸ í†µê³„ ê³„ì‚°"""
    collection_tag_counts = {}
    search_tag_counts = {}
    
    for chunk in chunks:
        # ìˆ˜ì§‘ íƒœê·¸ í†µê³„
        for tag in chunk.collection_tags:
            tag_lower = tag.lower()
            collection_tag_counts[tag_lower] = collection_tag_counts.get(tag_lower, 0) + 1
        
        # ê²€ìƒ‰ íƒœê·¸ í†µê³„
        for tag in chunk.search_tags:
            tag_lower = tag.lower()
            search_tag_counts[tag_lower] = search_tag_counts.get(tag_lower, 0) + 1
    
    return {
        "collection_tags": collection_tag_counts,
        "search_tags": search_tag_counts
    }

def calculate_similarity(query: str, chunk_content: str) -> float:
    """ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë²¡í„° ì„ë² ë”© ì‚¬ìš©)"""
    query_words = set(query.lower().split())
    content_words = set(chunk_content.lower().split())
    
    if not query_words or not content_words:
        return 0.0
    
    intersection = query_words.intersection(content_words)
    union = query_words.union(content_words)
    
    return len(intersection) / len(union) if union else 0.0

def search_and_generate_html(query: str, roadmap_documents: Dict[str, RoadmapDocument], threshold: float = 0.1) -> str:
    """ê²€ìƒ‰ì–´ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì²­í¬ë¥¼ ì°¾ì•„ ì¸í„°ë™í‹°ë¸Œ ë§ˆì¸ë“œë§µ HTMLì„ ì¬ìƒì„±í•©ë‹ˆë‹¤."""
    relevant_chunks = []
    
    # íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
    is_filename_search = query.startswith("filename:") or query.startswith("source:")
    
    # ëª¨ë“  ë¬¸ì„œì˜ ì²­í¬ì—ì„œ ê²€ìƒ‰
    for doc_id, document in roadmap_documents.items():
        for chunk in document.chunks:
            similarity = 0.0
            
            if is_filename_search:
                # íŒŒì¼ëª… ê²€ìƒ‰ì¸ ê²½ìš° íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰
                if query in chunk.collection_tags or query in chunk.search_tags:
                    similarity = 1.0  # ì™„ì „ ì¼ì¹˜
                elif query.lower() in [tag.lower() for tag in chunk.collection_tags + chunk.search_tags]:
                    similarity = 0.8  # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ì¼ì¹˜
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰
                similarity = calculate_similarity(query, chunk.content)
            
            if similarity >= threshold:
                relevant_chunks.append({
                    "chunk": chunk,
                    "similarity": similarity,
                    "document_title": document.title
                })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    relevant_chunks.sort(key=lambda x: x["similarity"], reverse=True)
    top_chunks = relevant_chunks[:20]  # ìƒìœ„ 20ê°œë¡œ ì¦ê°€
    
    if not top_chunks:
        return "<h1>ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤</h1>"
    
    # ì¤‘ë³µ ì œê±° ë° ê·¸ë£¹í™”
    unique_chunks = {}
    for item in top_chunks:
        chunk = item["chunk"]
        # ì²­í¬ IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        if chunk.id not in unique_chunks:
            unique_chunks[chunk.id] = item
        else:
            # ë” ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ê²ƒì„ ìœ ì§€
            if item["similarity"] > unique_chunks[chunk.id]["similarity"]:
                unique_chunks[chunk.id] = item
    
    # ì¤‘ë³µ ì œê±°ëœ ì²­í¬ë“¤ì„ ë‹¤ì‹œ ì •ë ¬
    unique_chunks_list = list(unique_chunks.values())
    unique_chunks_list.sort(key=lambda x: x["similarity"], reverse=True)
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
    categories = {
        "beginner": [],
        "intermediate": [],
        "advanced": [],
        "community": []
    }
    
    for item in unique_chunks_list:
        chunk = item["chunk"]
        category = chunk.metadata.get("category", "community").lower()
        if category in categories:
            categories[category].append(item)
        else:
            categories["community"].append(item)
    
    # HTML í…œí”Œë¦¿ (ì¸í„°ë™í‹°ë¸Œ ë§ˆì¸ë“œë§µ)
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{query} - ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ í•™ìŠµ ë¡œë“œë§µ</title>
        <style>
            body {{
                margin: 0;
                padding: 20px;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                overflow-x: auto;
            }}

            .mindmap-container {{
                background: rgba(255, 255, 255, 0.95);
                border-radius: 15px;
                padding: 30px;
                box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
                min-width: 1200px;
            }}

            .mindmap-title {{
                text-align: center;
                font-size: 2.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 30px;
                text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
            }}

            .search-info {{
                text-align: center;
                font-size: 1.2em;
                color: #34495e;
                margin-bottom: 20px;
                background: rgba(52, 152, 219, 0.1);
                padding: 15px;
                border-radius: 10px;
            }}

            .mindmap {{
                display: flex;
                flex-direction: column;
                align-items: center;
                gap: 30px;
            }}

            .root-node {{
                background: linear-gradient(135deg, #FF6B6B, #FF8E53);
                color: white;
                padding: 20px 40px;
                border-radius: 25px;
                font-size: 1.8em;
                font-weight: bold;
                box-shadow: 0 10px 25px rgba(255, 107, 107, 0.3);
                cursor: pointer;
                transition: all 0.3s ease;
            }}

            .root-node:hover {{
                transform: translateY(-5px);
                box-shadow: 0 15px 35px rgba(255, 107, 107, 0.4);
            }}

            .main-branches {{
                display: flex;
                justify-content: space-around;
                width: 100%;
                gap: 30px;
                flex-wrap: wrap;
            }}

            .branch {{
                flex: 1;
                min-width: 350px;
                max-width: 400px;
            }}

            .level-node {{
                padding: 15px 25px;
                border-radius: 20px;
                font-weight: bold;
                cursor: pointer;
                transition: all 0.3s ease;
                margin-bottom: 15px;
                text-align: center;
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }}

            .beginner {{
                background: linear-gradient(135deg, #4ECDC4, #44A08D);
                color: white;
            }}

            .intermediate {{
                background: linear-gradient(135deg, #FDBB2D, #22C1C3);
                color: white;
            }}

            .advanced {{
                background: linear-gradient(135deg, #FA8072, #FF6347);
                color: white;
            }}

            .community {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
            }}

            .level-node:hover {{
                transform: translateY(-3px);
                box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
            }}

            .sub-branches {{
                margin-left: 20px;
                margin-top: 15px;
                display: none;
            }}

            .sub-branches.expanded {{
                display: block;
                animation: slideDown 0.3s ease-out;
            }}

            @keyframes slideDown {{
                from {{
                    opacity: 0;
                    max-height: 0;
                }}
                to {{
                    opacity: 1;
                    max-height: 1000px;
                }}
            }}

            .sub-node {{
                background: rgba(255, 255, 255, 0.9);
                border-left: 4px solid #3498db;
                padding: 12px 20px;
                margin: 8px 0;
                border-radius: 8px;
                font-size: 0.95em;
                box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
                cursor: pointer;
                transition: all 0.2s ease;
            }}

            .sub-node:hover {{
                background: rgba(52, 152, 219, 0.1);
                transform: translateX(5px);
            }}

            .detail-node {{
                background: rgba(255, 255, 255, 0.7);
                border-left: 3px solid #95a5a6;
                padding: 8px 15px;
                margin: 5px 0 5px 20px;
                border-radius: 5px;
                font-size: 0.85em;
                color: #2c3e50;
            }}

            .resource-node {{
                background: rgba(46, 204, 113, 0.1);
                border-left: 3px solid #2ecc71;
                padding: 8px 15px;
                margin: 5px 0 5px 20px;
                border-radius: 5px;
                font-size: 0.85em;
                color: #27ae60;
            }}

            .similarity-score {{
                background: rgba(231, 76, 60, 0.1);
                border-left: 3px solid #e74c3c;
                padding: 8px 15px;
                margin: 5px 0 5px 20px;
                border-radius: 5px;
                font-size: 0.85em;
                color: #c0392b;
                font-weight: bold;
            }}

            .resource-node a {{
                color: #2980b9;
                text-decoration: underline;
                font-weight: 500;
                transition: all 0.2s ease;
                padding: 2px 4px;
                border-radius: 3px;
                background: rgba(41, 128, 185, 0.1);
            }}

            .resource-node a:hover {{
                color: #ffffff;
                background: #3498db;
                text-decoration: none;
                transform: translateX(3px);
                box-shadow: 0 2px 8px rgba(52, 152, 219, 0.3);
            }}

            .expand-icon {{
                float: right;
                transition: transform 0.3s ease;
            }}

            .expand-icon.rotated {{
                transform: rotate(90deg);
            }}

            .controls {{
                text-align: center;
                margin-bottom: 20px;
            }}

            .btn {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 25px;
                cursor: pointer;
                margin: 0 10px;
                font-size: 0.9em;
                transition: all 0.3s ease;
            }}

            .btn:hover {{
                transform: translateY(-2px);
                box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
            }}
        </style>
    </head>
    <body>
        <div class="mindmap-container">
            <h1 class="mindmap-title">{query} í•™ìŠµ ë¡œë“œë§µ</h1>
            
            <div class="search-info">
                ğŸ” ê²€ìƒ‰ì–´: <strong>{query}</strong> | ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: <strong>{len(unique_chunks_list)}ê°œ</strong> | 
                ğŸ“š ì†ŒìŠ¤ ë¬¸ì„œ: <strong>{len(set(item['chunk'].roadmap_id for item in unique_chunks_list))}ê°œ</strong>
            </div>

            <div class="controls">
                <button class="btn" onclick="expandAll()">ì „ì²´ í¼ì¹˜ê¸°</button>
                <button class="btn" onclick="collapseAll()">ì „ì²´ ì ‘ê¸°</button>
            </div>

            <div class="mindmap">
                <div class="root-node" onclick="toggleAllBranches()">
                    {query} í•™ìŠµ ë¡œë“œë§µ
                </div>

                <div class="main-branches" id="mainBranches" style="display: none;">
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¸Œëœì¹˜ ìƒì„±
    category_names = {
        "beginner": "ì´ˆê¸‰ (Beginner)",
        "intermediate": "ì¤‘ê¸‰ (Intermediate)", 
        "advanced": "ê³ ê¸‰ (Advanced)",
        "community": "ì»¤ë®¤ë‹ˆí‹° (Community)"
    }
    
    for category, items in categories.items():
        if items:  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— í•­ëª©ì´ ìˆëŠ” ê²½ìš°ë§Œ
            html_content += f"""
                    <div class="branch">
                        <div class="level-node {category}" onclick="toggleBranch('{category}')">
                            {category_names[category]} <span class="expand-icon">â–¶</span>
                        </div>
                        <div class="sub-branches" id="{category}">
                            <div class="sub-node" onclick="toggleSubBranch('{category}-details')">
                                ê²€ìƒ‰ ê²°ê³¼ <span class="expand-icon">â–¶</span>
                            </div>
                            <div class="sub-branches" id="{category}-details">
            """
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì²­í¬ë“¤ì„ ì¶”ê°€ (ì¤‘ë³µ ì œê±°ëœ)
            for i, item in enumerate(items[:8]):  # ê° ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 8ê°œë¡œ ì œí•œ
                chunk = item["chunk"]
                similarity = item["similarity"]
                section = chunk.metadata.get("section", "N/A")
                content = chunk.content[:150] + "..." if len(chunk.content) > 150 else chunk.content
                
                # HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                section_escaped = html.escape(section)
                content_escaped = html.escape(content)
                
                html_content += f"""
                                <div class="detail-node">{section_escaped}</div>
                                <div class="detail-node">{content_escaped}</div>
                                <div class="similarity-score">ìœ ì‚¬ë„: {similarity:.2f}</div>
                """
                
                # ë¦¬ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ì¶”ê°€ (ë§í¬ ì²˜ë¦¬ ê°œì„ )
                resources = chunk.metadata.get("resources", [])
                if resources:
                    for resource in resources[:3]:  # ìµœëŒ€ 3ê°œ ë¦¬ì†ŒìŠ¤
                        if isinstance(resource, dict):
                            title = resource.get("title", "ë¦¬ì†ŒìŠ¤")
                            url = resource.get("url", "#")
                            # URL ìœ íš¨ì„± ê²€ì‚¬
                            if url and url != "#" and (url.startswith("http://") or url.startswith("https://")):
                                title_escaped = html.escape(title)
                                url_escaped = html.escape(url)
                                html_content += f'<div class="resource-node">ğŸ”— <a href="{url_escaped}" target="_blank" rel="noopener noreferrer">{title_escaped}</a></div>'
                            else:
                                title_escaped = html.escape(title)
                                html_content += f'<div class="resource-node">ğŸ“š {title_escaped}</div>'
                        else:
                            # ë¬¸ìì—´ì¸ ê²½ìš°
                            resource_text = html.escape(str(resource))
                            html_content += f'<div class="resource-node">ğŸ“š {resource_text}</div>'
                
                # ë„êµ¬ ì •ë³´ ì¶”ê°€
                tools = chunk.metadata.get("tools", [])
                if tools:
                    tools_text = ", ".join(tools[:3])  # ìµœëŒ€ 3ê°œ ë„êµ¬
                    tools_escaped = html.escape(tools_text)
                    html_content += f'<div class="detail-node">ğŸ”§ ë„êµ¬: {tools_escaped}</div>'
                
                # í•™ìŠµ ëª©í‘œ ì¶”ê°€
                learning_objectives = chunk.metadata.get("learning_objectives", [])
                if learning_objectives:
                    for objective in learning_objectives[:2]:  # ìµœëŒ€ 2ê°œ ëª©í‘œ
                        objective_escaped = html.escape(objective)
                        html_content += f'<div class="detail-node">ğŸ¯ {objective_escaped}</div>'
            
            html_content += """
                            </div>
                        </div>
                    </div>
            """
    
    html_content += """
                </div>
            </div>
        </div>

        <script>
            let mainBranchesVisible = false;

            function toggleAllBranches() {
                const mainBranches = document.getElementById('mainBranches');
                mainBranchesVisible = !mainBranchesVisible;
                mainBranches.style.display = mainBranchesVisible ? 'flex' : 'none';
            }

            function toggleBranch(branchId) {
                const branch = document.getElementById(branchId);
                const icon = event.currentTarget.querySelector('.expand-icon');
                
                if (branch.style.display === 'none' || branch.style.display === '') {
                    branch.style.display = 'block';
                    branch.classList.add('expanded');
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                } else {
                    branch.style.display = 'none';
                    branch.classList.remove('expanded');
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                }
            }

            function toggleSubBranch(subBranchId) {
                const subBranch = document.getElementById(subBranchId);
                const icon = event.currentTarget.querySelector('.expand-icon');
                
                if (subBranch.style.display === 'none' || subBranch.style.display === '') {
                    subBranch.style.display = 'block';
                    subBranch.classList.add('expanded');
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                } else {
                    subBranch.style.display = 'none';
                    subBranch.classList.remove('expanded');
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                }
            }

            function expandAll() {
                const mainBranches = document.getElementById('mainBranches');
                mainBranches.style.display = 'flex';
                mainBranchesVisible = true;

                const allBranches = document.querySelectorAll('.sub-branches');
                const allIcons = document.querySelectorAll('.expand-icon');
                
                allBranches.forEach(branch => {
                    branch.style.display = 'block';
                    branch.classList.add('expanded');
                });
                
                allIcons.forEach(icon => {
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                });
            }

            function collapseAll() {
                const mainBranches = document.getElementById('mainBranches');
                mainBranches.style.display = 'none';
                mainBranchesVisible = false;

                const allBranches = document.querySelectorAll('.sub-branches');
                const allIcons = document.querySelectorAll('.expand-icon');
                
                allBranches.forEach(branch => {
                    branch.style.display = 'none';
                    branch.classList.remove('expanded');
                });
                
                allIcons.forEach(icon => {
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                });
            }
        </script>
    </body>
    </html>
    """
    
    return html_content

def generate_mindmap_html(roadmap_data: Dict[str, Any]) -> str:
    """ë¡œë“œë§µ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸í„°ë™í‹°ë¸Œ ë§ˆì¸ë“œë§µ HTMLì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # ë©”ì¸ í† í”½
    main_topic = html.escape(roadmap_data.get('main_topic', 'í•™ìŠµ ë¡œë“œë§µ'))
    
    # ì‚¬ì „ ìš”êµ¬ì‚¬í•­
    prerequisites_html = ""
    if roadmap_data.get('prerequisites'):
        prerequisites_list = ""
        for req in roadmap_data['prerequisites']:
            prerequisites_list += f'<div class="detail-node">{html.escape(req)}</div>'
        prerequisites_html = f"""
        <div class="branch">
            <div class="level-node beginner" onclick="toggleBranch('prerequisites')">
                ì‚¬ì „ ìš”êµ¬ì‚¬í•­ <span class="expand-icon">â–¶</span>
            </div>
            <div class="sub-branches" id="prerequisites">
                <div class="sub-node" onclick="toggleSubBranch('prerequisites-details')">
                    í•„ìˆ˜ ì„ ìˆ˜ ì§€ì‹ <span class="expand-icon">â–¶</span>
                </div>
                <div class="sub-branches" id="prerequisites-details">
                    {prerequisites_list}
                </div>
            </div>
        </div>
        """
    
    # ë‹¨ê³„ë³„ ë‚´ìš©
    phases_html = ""
    for i, phase in enumerate(roadmap_data.get('phases', [])):
        phase_title = html.escape(phase.get('title', f'ë‹¨ê³„ {i+1}'))
        duration = html.escape(phase.get('duration', ''))
        
        topics_html = ""
        for j, topic in enumerate(phase.get('topics', [])):
            topic_title = html.escape(topic.get('title', ''))
            topic_desc = html.escape(topic.get('description', ''))
            
            # í•™ìŠµ ë§í¬ ì²˜ë¦¬
            learning_links_html = ""
            if topic.get('learning_links'):
                for link in topic['learning_links']:
                    link_title = html.escape(link.get('title', 'í•™ìŠµ ë§í¬'))
                    link_url = html.escape(link.get('url', '#'))
                    learning_links_html += f'<div class="resource-node">ğŸ”— <a href="{link_url}" target="_blank">{link_title}</a></div>'
            
            topics_html += f"""
            <div class="detail-node">{topic_title}</div>
            <div class="detail-node">{topic_desc}</div>
            {learning_links_html}
            """
        
        # ë‹¨ê³„ë³„ í´ë˜ìŠ¤ ê²°ì •
        phase_class = "beginner" if i == 0 else "intermediate" if i == 1 else "advanced"
        
        phases_html += f"""
        <div class="branch">
            <div class="level-node {phase_class}" onclick="toggleBranch('phase-{i}')">
                {phase_title} {f'({duration})' if duration else ''} <span class="expand-icon">â–¶</span>
            </div>
            <div class="sub-branches" id="phase-{i}">
                <div class="sub-node" onclick="toggleSubBranch('topics-{i}')">
                    í•™ìŠµ ì£¼ì œ <span class="expand-icon">â–¶</span>
                </div>
                <div class="sub-branches" id="topics-{i}">
                    {topics_html}
                </div>
            </div>
        </div>
        """
    
    # ì¶”ì²œ ìë£Œ
    resources_html = ""
    if roadmap_data.get('resources'):
        resources_list = ""
        for res in roadmap_data['resources']:
            resources_list += f'<div class="resource-node">ğŸ“š {html.escape(res)}</div>'
        resources_html = f"""
        <div class="branch">
            <div class="level-node community" onclick="toggleBranch('resources')">
                ì¶”ì²œ í•™ìŠµ ìë£Œ <span class="expand-icon">â–¶</span>
            </div>
            <div class="sub-branches" id="resources">
                {resources_list}
            </div>
        </div>
        """
    
    # HTML í…œí”Œë¦¿ (ì¸í„°ë™í‹°ë¸Œ ë§ˆì¸ë“œë§µ)
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{main_topic} - ì¸í„°ë™í‹°ë¸Œ ë§ˆì¸ë“œë§µ</title>
        <style>
            body {{
                margin: 0;
                padding: 20px;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                overflow-x: auto;
            }}

            .mindmap-container {{
                background: rgba(255, 255, 255, 0.95);
                border-radius: 15px;
                padding: 30px;
                box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
                min-width: 1200px;
            }}

            .mindmap-title {{
                text-align: center;
                font-size: 2.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 30px;
                text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
            }}

            .mindmap {{
                display: flex;
                flex-direction: column;
                align-items: center;
                gap: 30px;
            }}

            .root-node {{
                background: linear-gradient(135deg, #FF6B6B, #FF8E53);
                color: white;
                padding: 20px 40px;
                border-radius: 25px;
                font-size: 1.8em;
                font-weight: bold;
                box-shadow: 0 10px 25px rgba(255, 107, 107, 0.3);
                cursor: pointer;
                transition: all 0.3s ease;
            }}

            .root-node:hover {{
                transform: translateY(-5px);
                box-shadow: 0 15px 35px rgba(255, 107, 107, 0.4);
            }}

            .main-branches {{
                display: flex;
                justify-content: space-around;
                width: 100%;
                gap: 30px;
                flex-wrap: wrap;
            }}

            .branch {{
                flex: 1;
                min-width: 350px;
                max-width: 400px;
            }}

            .level-node {{
                padding: 15px 25px;
                border-radius: 20px;
                font-weight: bold;
                cursor: pointer;
                transition: all 0.3s ease;
                margin-bottom: 15px;
                text-align: center;
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }}

            .beginner {{
                background: linear-gradient(135deg, #4ECDC4, #44A08D);
                color: white;
            }}

            .intermediate {{
                background: linear-gradient(135deg, #FDBB2D, #22C1C3);
                color: white;
            }}

            .advanced {{
                background: linear-gradient(135deg, #FA8072, #FF6347);
                color: white;
            }}

            .community {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
            }}

            .level-node:hover {{
                transform: translateY(-3px);
                box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
            }}

            .sub-branches {{
                margin-left: 20px;
                margin-top: 15px;
                display: none;
            }}

            .sub-branches.expanded {{
                display: block;
                animation: slideDown 0.3s ease-out;
            }}

            @keyframes slideDown {{
                from {{
                    opacity: 0;
                    max-height: 0;
                }}
                to {{
                    opacity: 1;
                    max-height: 1000px;
                }}
            }}

            .sub-node {{
                background: rgba(255, 255, 255, 0.9);
                border-left: 4px solid #3498db;
                padding: 12px 20px;
                margin: 8px 0;
                border-radius: 8px;
                font-size: 0.95em;
                box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
                cursor: pointer;
                transition: all 0.2s ease;
            }}

            .sub-node:hover {{
                background: rgba(52, 152, 219, 0.1);
                transform: translateX(5px);
            }}

            .detail-node {{
                background: rgba(255, 255, 255, 0.7);
                border-left: 3px solid #95a5a6;
                padding: 8px 15px;
                margin: 5px 0 5px 20px;
                border-radius: 5px;
                font-size: 0.85em;
                color: #2c3e50;
            }}

            .resource-node {{
                background: rgba(46, 204, 113, 0.1);
                border-left: 3px solid #2ecc71;
                padding: 8px 15px;
                margin: 5px 0 5px 20px;
                border-radius: 5px;
                font-size: 0.85em;
                color: #27ae60;
            }}

            .resource-node a {{
                color: #2980b9;
                text-decoration: underline;
                font-weight: 500;
                transition: all 0.2s ease;
                padding: 2px 4px;
                border-radius: 3px;
                background: rgba(41, 128, 185, 0.1);
            }}

            .resource-node a:hover {{
                color: #ffffff;
                background: #3498db;
                text-decoration: none;
                transform: translateX(3px);
                box-shadow: 0 2px 8px rgba(52, 152, 219, 0.3);
            }}

            .expand-icon {{
                float: right;
                transition: transform 0.3s ease;
            }}

            .expand-icon.rotated {{
                transform: rotate(90deg);
            }}

            .controls {{
                text-align: center;
                margin-bottom: 20px;
            }}

            .btn {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 25px;
                cursor: pointer;
                margin: 0 10px;
                font-size: 0.9em;
                transition: all 0.3s ease;
            }}

            .btn:hover {{
                transform: translateY(-2px);
                box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
            }}
        </style>
    </head>
    <body>
        <div class="mindmap-container">
            <h1 class="mindmap-title">{main_topic}</h1>

            <div class="controls">
                <button class="btn" onclick="expandAll()">ì „ì²´ í¼ì¹˜ê¸°</button>
                <button class="btn" onclick="collapseAll()">ì „ì²´ ì ‘ê¸°</button>
            </div>

            <div class="mindmap">
                <div class="root-node" onclick="toggleAllBranches()">
                    {main_topic}
                </div>

                <div class="main-branches" id="mainBranches" style="display: none;">
                    {prerequisites_html}
                    {phases_html}
                    {resources_html}
                </div>
            </div>
        </div>

        <script>
            let mainBranchesVisible = false;

            function toggleAllBranches() {{
                const mainBranches = document.getElementById('mainBranches');
                mainBranchesVisible = !mainBranchesVisible;
                mainBranches.style.display = mainBranchesVisible ? 'flex' : 'none';
            }}

            function toggleBranch(branchId) {{
                const branch = document.getElementById(branchId);
                const icon = event.currentTarget.querySelector('.expand-icon');
                
                if (branch.style.display === 'none' || branch.style.display === '') {{
                    branch.style.display = 'block';
                    branch.classList.add('expanded');
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                }} else {{
                    branch.style.display = 'none';
                    branch.classList.remove('expanded');
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                }}
            }}

            function toggleSubBranch(subBranchId) {{
                const subBranch = document.getElementById(subBranchId);
                const icon = event.currentTarget.querySelector('.expand-icon');
                
                if (subBranch.style.display === 'none' || subBranch.style.display === '') {{
                    subBranch.style.display = 'block';
                    subBranch.classList.add('expanded');
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                }} else {{
                    subBranch.style.display = 'none';
                    subBranch.classList.remove('expanded');
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                }}
            }}

            function expandAll() {{
                const mainBranches = document.getElementById('mainBranches');
                mainBranches.style.display = 'flex';
                mainBranchesVisible = true;

                const allBranches = document.querySelectorAll('.sub-branches');
                const allIcons = document.querySelectorAll('.expand-icon');
                
                allBranches.forEach(branch => {{
                    branch.style.display = 'block';
                    branch.classList.add('expanded');
                }});
                
                allIcons.forEach(icon => {{
                    icon.classList.add('rotated');
                    icon.innerHTML = 'â–¼';
                }});
            }}

            function collapseAll() {{
                const mainBranches = document.getElementById('mainBranches');
                mainBranches.style.display = 'none';
                mainBranchesVisible = false;

                const allBranches = document.querySelectorAll('.sub-branches');
                const allIcons = document.querySelectorAll('.expand-icon');
                
                allBranches.forEach(branch => {{
                    branch.style.display = 'none';
                    branch.classList.remove('expanded');
                }});
                
                allIcons.forEach(icon => {{
                    icon.classList.remove('rotated');
                    icon.innerHTML = 'â–¶';
                }});
            }}
        </script>
    </body>
    </html>
    """
    
    return html_content

# í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ—ºï¸ í•™ìŠµë¡œë“œë§µ ì‹œìŠ¤í…œ</h1>
    <p>AI ê¸°ë°˜ ê°œì¸í™” í•™ìŠµ ê²½ë¡œ ìƒì„± ë° ê´€ë¦¬</p>
</div>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
with st.sidebar:
    st.title("ğŸ§­ ë„¤ë¹„ê²Œì´ì…˜")
    page = st.selectbox(
        "í˜ì´ì§€ ì„ íƒ",
        ["ë©”ì¸ ëŒ€ì‹œë³´ë“œ", "ë¡œë“œë§µ ìƒì„±/ì¡°íšŒ", "HTML ì—…ë¡œë“œ/íŒŒì‹±", "DB â†’ HTML ì¬ìƒì„±", "AI ë°°ì¹˜ ê²€ì¦/ë³´ì™„", "ë³€ê²½ ë¡œê·¸/ì´ë ¥"]
    )
    st.markdown("---")
    chatgpt_model = st.selectbox("ChatGPT ëª¨ë¸ëª…", ["gpt-3.5-turbo", "gpt-4", "gpt-4o"], index=0)
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    st.session_state["chatgpt_model"] = chatgpt_model
    st.session_state["openai_api_key"] = openai_api_key

# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
if page == "ë©”ì¸ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ“Š ë©”ì¸ ëŒ€ì‹œë³´ë“œ")
    
    # ì£¼ìš” ì§€í‘œ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìƒì„±ëœ ë¡œë“œë§µ", "24", "â†—ï¸ 3")
    with col2:
        st.metric("í•™ìŠµ ìš”ì†Œ", "156", "â†—ï¸ 12")
    with col3:
        st.metric("ê²€ì¦ ì™„ë£Œ", "89", "â†—ï¸ 8")
    
    # ë¹ ë¥¸ ì‹¤í–‰
    st.subheader("ğŸš€ ë¹ ë¥¸ ì‹¤í–‰")
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("+ ìƒˆ ë¡œë“œë§µ ìƒì„±", type="primary"):
            st.success("ë¡œë“œë§µ ìƒì„± í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤")
    with col2:
        if st.button("ğŸ”„ ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰"):
            st.session_state.validation_progress = 67
            st.success("ë°°ì¹˜ ê²€ì¦ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")
    with col3:
        if st.button("ğŸ”§ AI ë³´ì™„ ì‹¤í–‰"):
            st.success("AI ë³´ì™„ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    # ìµœê·¼ ìƒì„± ë¡œë“œë§µ
    st.subheader("ğŸ“‹ ìµœê·¼ ìƒì„± ë¡œë“œë§µ")
    recent_roadmaps = pd.DataFrame({
        "ì£¼ì œ": ["React ê¸°ì´ˆí•™ìŠµ", "Python ë°ì´í„°ë¶„ì„", "JavaScript ES6+"],
        "ìƒì„±ì‹œê°„": ["2ì‹œê°„ ì „", "1ì¼ ì „", "3ì¼ ì „"],
        "ìƒíƒœ": ["ì™„ë£Œ", "ì™„ë£Œ", "ì™„ë£Œ"]
    })
    st.dataframe(recent_roadmaps, use_container_width=True)
    
    # í†µê³„ ì°¨íŠ¸
    st.subheader("ğŸ“ˆ í•™ìŠµ í†µê³„")
    col1, col2 = st.columns(2)
    
    with col1:
        # ì›”ë³„ ë¡œë“œë§µ ìƒì„± ì¶”ì´
        chart_data = pd.DataFrame({
            "ì›”": ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”"],
            "ìƒì„± ìˆ˜": [5, 8, 12, 15, 24]
        })
        fig = px.line(chart_data, x="ì›”", y="ìƒì„± ìˆ˜", title="ì›”ë³„ ë¡œë“œë§µ ìƒì„± ì¶”ì´")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ì£¼ì œë³„ ë¶„í¬
        subject_data = pd.DataFrame({
            "ì£¼ì œ": ["React", "Python", "JavaScript", "Java", "ê¸°íƒ€"],
            "ê°œìˆ˜": [8, 6, 4, 3, 3]
        })
        fig = px.pie(subject_data, values="ê°œìˆ˜", names="ì£¼ì œ", title="ì£¼ì œë³„ ë¡œë“œë§µ ë¶„í¬")
        st.plotly_chart(fig, use_container_width=True)

# ë¡œë“œë§µ ìƒì„±/ì¡°íšŒ
elif page == "ë¡œë“œë§µ ìƒì„±/ì¡°íšŒ":
    st.header("ğŸ¤– ë¡œë“œë§µ ìƒì„±/ì¡°íšŒ")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“ AI ë¡œë“œë§µ ìƒì„±", "ğŸ“š ìƒì„±ëœ ë¡œë“œë§µ ì¡°íšŒ"])
    
    with tab1:
        st.subheader("ğŸ“ AI ë¡œë“œë§µ ìƒì„±")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ¯ í•™ìŠµ ì£¼ì œ ì…ë ¥")
            
            topic = st.text_input(
                "í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                placeholder="ì˜ˆ: Python í”„ë¡œê·¸ë˜ë°, ë¨¸ì‹ ëŸ¬ë‹, ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„ ë“±",
                help="êµ¬ì²´ì ì¸ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë¡œë“œë§µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
            
            # ì„¤ì • ìƒíƒœ í™•ì¸
            api_key = st.session_state.get("openai_api_key", "")
            selected_model = st.session_state.get("chatgpt_model", "gpt-3.5-turbo")
            
            if not api_key:
                st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”")
            
            st.info(f"ğŸ“‹ ì„ íƒëœ ëª¨ë¸: {selected_model}")
            
            st.markdown("---")
            st.markdown("### ğŸ’¡ ì‚¬ìš© ë°©ë²•")
            st.markdown("""
            1. ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
            2. ì‚¬ì´ë“œë°”ì—ì„œ ChatGPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
            3. í•™ìŠµí•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”
            4. 'ë¡œë“œë§µ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
            """)
        
        with col2:
            st.subheader("ğŸš€ ë¡œë“œë§µ ìƒì„±")
            
            # ì„¤ì • ìƒíƒœ í™•ì¸
            if not st.session_state.get("openai_api_key"):
                st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”")
            
            st.markdown("<br>", unsafe_allow_html=True)
            generate_button = st.button("ğŸš€ ë¡œë“œë§µ ìƒì„±", type="primary", disabled=not st.session_state.get("openai_api_key"))
        
        # ë¡œë“œë§µ ìƒì„±
        if generate_button:
            if not api_key:
                st.error("âŒ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not topic:
                st.error("í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë¡œë“œë§µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ìµœëŒ€ 2ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                    try:
                        # learning_roadmap_generator.pyì˜ í•¨ìˆ˜ë“¤ import
                        import openai
                        import json
                        import html
                        from typing import Dict, List, Any
                        
                        def call_chatgpt_api(api_key: str, model: str, topic: str) -> Dict[str, Any]:
                            """ChatGPT APIë¥¼ í˜¸ì¶œí•˜ì—¬ í•™ìŠµ ë¡œë“œë§µì„ ìƒì„±í•©ë‹ˆë‹¤."""
                            try:
                                # ì§„í–‰ ìƒí™© í‘œì‹œ
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                status_text.text("API ì—°ê²° ì¤‘...")
                                progress_bar.progress(25)
                                # httpx í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì—¬ í”„ë¡ì‹œ ë¬¸ì œ í•´ê²°
                                import httpx
                                
                                # í”„ë¡ì‹œ ì„¤ì • ì—†ì´ httpx í´ë¼ì´ì–¸íŠ¸ ìƒì„± (timeout ì¦ê°€)
                                http_client = httpx.Client(
                                    timeout=httpx.Timeout(120.0),  # 2ë¶„ìœ¼ë¡œ ì¦ê°€
                                    limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
                                )
                                
                                # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                                client = openai.OpenAI(
                                    api_key=api_key,
                                    http_client=http_client
                                )
                                
                                status_text.text("ChatGPT API í˜¸ì¶œ ì¤‘...")
                                progress_bar.progress(50)
                                
                                prompt = f"""
                                ì£¼ì œ "{topic}"ì— ëŒ€í•œ ì²´ê³„ì ì¸ í•™ìŠµ ë¡œë“œë§µì„ ìƒì„±í•´ì£¼ì„¸ìš”.
                                
                                ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
                                {{
                                    "main_topic": "ì£¼ì œëª…",
                                    "prerequisites": ["ì‚¬ì „ ìš”êµ¬ì‚¬í•­1", "ì‚¬ì „ ìš”êµ¬ì‚¬í•­2"],
                                    "phases": [
                                        {{
                                            "title": "ë‹¨ê³„ëª…",
                                            "duration": "ì˜ˆìƒ ì†Œìš”ì‹œê°„",
                                            "topics": [
                                                {{
                                                    "title": "ì„¸ë¶€ ì£¼ì œëª…",
                                                    "description": "ì„¸ë¶€ ì£¼ì œ ì„¤ëª…",
                                                    "learning_links": [
                                                        {{
                                                            "title": "ê´€ë ¨ í•™ìŠµ ë§í¬ ì œëª©",
                                                            "url": "https://example.com/learning-resource"
                                                        }}
                                                    ]
                                                }}
                                            ]
                                        }}
                                    ],
                                    "resources": ["ì¶”ì²œ ìë£Œ1", "ì¶”ì²œ ìë£Œ2"]
                                }}
                                
                                ê° ë‹¨ê³„ëŠ” ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì¹˜í•˜ê³ , ì´ˆë³´ìë¶€í„° ê³ ê¸‰ìê¹Œì§€ ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•´ì£¼ì„¸ìš”.
                                ê° ì£¼ì œë§ˆë‹¤ ê´€ë ¨ëœ ìœ ìš©í•œ í•™ìŠµ ë§í¬(ì˜¨ë¼ì¸ ê°•ì˜, ë¬¸ì„œ, íŠœí† ë¦¬ì–¼ ë“±)ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
                                """
                                
                                response = client.chat.completions.create(
                                    model=model,
                                    messages=[
                                        {"role": "system", "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ì´ê³  íš¨ê³¼ì ì¸ í•™ìŠµ ë¡œë“œë§µì„ ì œê³µí•©ë‹ˆë‹¤."},
                                        {"role": "user", "content": prompt}
                                    ],
                                    max_tokens=3000,  # í† í° ìˆ˜ ì¦ê°€
                                    temperature=0.7,
                                    timeout=120  # API í˜¸ì¶œ timeout ì„¤ì •
                                )
                                
                                status_text.text("ì‘ë‹µ ì²˜ë¦¬ ì¤‘...")
                                progress_bar.progress(75)
                                
                                content = response.choices[0].message.content
                                
                                # JSON íŒŒì‹± ì‹œë„
                                try:
                                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                                    if "```json" in content:
                                        content = content.split("```json")[1].split("```")[0]
                                    elif "```" in content:
                                        content = content.split("```")[1].split("```")[0]
                                    
                                    roadmap_data = json.loads(content.strip())
                                    
                                    status_text.text("ë¡œë“œë§µ ìƒì„± ì™„ë£Œ!")
                                    progress_bar.progress(100)
                                    
                                    return roadmap_data
                                    
                                except json.JSONDecodeError:
                                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
                                    status_text.text("JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ êµ¬ì¡° ìƒì„± ì¤‘...")
                                    progress_bar.progress(90)
                                    
                                    return {
                                        "main_topic": topic,
                                        "prerequisites": ["ê¸°ë³¸ì ì¸ í•™ìŠµ ì˜ì§€", "ê¾¸ì¤€í•œ í•™ìŠµ ì‹œê°„ í™•ë³´"],
                                        "phases": [
                                            {
                                                "title": "ê¸°ì´ˆ ë‹¨ê³„",
                                                "duration": "2-4ì£¼",
                                                "topics": [
                                                    {"title": "ê¸°ë³¸ ê°œë… ì´í•´", "description": content[:200] + "..."}
                                                ]
                                            }
                                        ],
                                        "resources": ["ì˜¨ë¼ì¸ ê°•ì˜", "ê´€ë ¨ ì„œì ", "ì‹¤ìŠµ ìë£Œ"]
                                    }
                                    
                            except Exception as e:
                                # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                                progress_bar.progress(0)
                                status_text.text("ì˜¤ë¥˜ ë°œìƒ")
                                
                                st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                                # ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ í‘œì‹œ
                                st.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                                st.error(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
                                
                                # timeout ê´€ë ¨ ì•ˆë‚´
                                if "timeout" in str(e).lower() or "timed out" in str(e).lower():
                                    st.warning("âš ï¸ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:")
                                    st.markdown("""
                                    - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”
                                    - ë” ê°„ë‹¨í•œ ì£¼ì œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”
                                    - ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”
                                    - ë‹¤ë¥¸ ChatGPT ëª¨ë¸ì„ ì„ íƒí•´ë³´ì„¸ìš”
                                    """)
                                
                                # ëŒ€ì•ˆ: ê¸°ë³¸ ë¡œë“œë§µ ìƒì„±
                                st.warning("ê¸°ë³¸ ë¡œë“œë§µì„ ìƒì„±í•©ë‹ˆë‹¤.")
                                return {
                                    "main_topic": topic,
                                    "prerequisites": ["ê¸°ë³¸ì ì¸ í•™ìŠµ ì˜ì§€", "ê¾¸ì¤€í•œ í•™ìŠµ ì‹œê°„ í™•ë³´"],
                                    "phases": [
                                        {
                                            "title": "ê¸°ì´ˆ ë‹¨ê³„",
                                            "duration": "2-4ì£¼",
                                            "topics": [
                                                {"title": "ê¸°ë³¸ ê°œë… ì´í•´", "description": f"{topic}ì˜ ê¸°ë³¸ ê°œë…ì„ í•™ìŠµí•©ë‹ˆë‹¤."},
                                                {"title": "í•µì‹¬ ì›ë¦¬ íŒŒì•…", "description": f"{topic}ì˜ í•µì‹¬ ì›ë¦¬ë¥¼ ì´í•´í•©ë‹ˆë‹¤."}
                                            ]
                                        },
                                        {
                                            "title": "ì¤‘ê¸‰ ë‹¨ê³„",
                                            "duration": "4-8ì£¼",
                                            "topics": [
                                                {"title": "ì‹¤ìŠµ ë° ì ìš©", "description": f"{topic}ì„ ì‹¤ì œë¡œ ì ìš©í•´ë´…ë‹ˆë‹¤."},
                                                {"title": "ë¬¸ì œ í•´ê²°", "description": f"{topic} ê´€ë ¨ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤."}
                                            ]
                                        },
                                        {
                                            "title": "ê³ ê¸‰ ë‹¨ê³„",
                                            "duration": "8-12ì£¼",
                                            "topics": [
                                                {"title": "ì‹¬í™” í•™ìŠµ", "description": f"{topic}ì˜ ê³ ê¸‰ ê°œë…ì„ í•™ìŠµí•©ë‹ˆë‹¤."},
                                                {"title": "í”„ë¡œì íŠ¸ ìˆ˜í–‰", "description": f"{topic}ì„ í™œìš©í•œ ì‹¤ì œ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."}
                                            ]
                                        }
                                    ],
                                    "resources": ["ì˜¨ë¼ì¸ ê°•ì˜", "ê´€ë ¨ ì„œì ", "ì‹¤ìŠµ ìë£Œ", "ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬"]
                                }
                            finally:
                                # httpx í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
                                if 'http_client' in locals():
                                    http_client.close()
                                
                                # ì§„í–‰ ìƒí™© ì •ë¦¬
                                if 'progress_bar' in locals():
                                    progress_bar.empty()
                                if 'status_text' in locals():
                                    status_text.empty()
                        

                        
                        # ë¡œë“œë§µ ìƒì„±
                        roadmap_data = call_chatgpt_api(api_key, selected_model, topic)
                        
                        if roadmap_data:
                            st.success("ë¡œë“œë§µì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            
                            # ë§ˆì¸ë“œë§µ HTML ìƒì„±
                            mindmap_html = generate_mindmap_html(roadmap_data)
                            
                            # HTML í‘œì‹œ
                            st.components.v1.html(mindmap_html, height=800, scrolling=True)
                            
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            st.download_button(
                                label="ğŸ“¥ HTML íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=mindmap_html,
                                file_name=f"{topic}_roadmap.html",
                                mime="text/html",
                                key=f"download_ai_generated_{topic}"
                            )
                            
                            # ì›ë³¸ ë°ì´í„° í‘œì‹œ (ì„ íƒì‚¬í•­)
                            with st.expander("ğŸ“„ ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
                                st.json(roadmap_data)
                            
                            # ì„¸ì…˜ì— ì €ì¥
                            new_roadmap = {
                                "ì£¼ì œ": topic,
                                "ë‚œì´ë„": "AI ìƒì„±",
                                "ì¤‘ì ë¶„ì•¼": "AI ê¸°ë°˜",
                                "ìƒì„±ì‹œê°„": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "ë°ì´í„°": roadmap_data
                            }
                            st.session_state.roadmaps.append(new_roadmap)
                            
                    except Exception as e:
                        st.error(f"ë¡œë“œë§µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    with tab2:
        st.subheader("ğŸ“š ìƒì„±ëœ ë¡œë“œë§µ ì¡°íšŒ")
        
        if st.session_state.roadmaps:
            # ë¡œë“œë§µ ëª©ë¡ í‘œì‹œ
            roadmaps_df = pd.DataFrame([
                {
                    "ì£¼ì œ": roadmap["ì£¼ì œ"],
                    "ë‚œì´ë„": roadmap["ë‚œì´ë„"],
                    "ì¤‘ì ë¶„ì•¼": roadmap["ì¤‘ì ë¶„ì•¼"],
                    "ìƒì„±ì‹œê°„": roadmap["ìƒì„±ì‹œê°„"]
                }
                for roadmap in st.session_state.roadmaps
            ])
            st.dataframe(roadmaps_df, use_container_width=True)
            
            # ìƒì„¸ ì¡°íšŒ
            if st.session_state.roadmaps:
                st.subheader("ğŸ” ìƒì„¸ ì¡°íšŒ")
                selected_roadmap_idx = st.selectbox(
                    "ì¡°íšŒí•  ë¡œë“œë§µ ì„ íƒ:",
                    options=range(len(st.session_state.roadmaps)),
                    format_func=lambda x: f"{st.session_state.roadmaps[x]['ì£¼ì œ']} ({st.session_state.roadmaps[x]['ìƒì„±ì‹œê°„']})"
                )
                
                if selected_roadmap_idx is not None:
                    selected_roadmap = st.session_state.roadmaps[selected_roadmap_idx]
                    
                    col_info1, col_info2, col_info3 = st.columns(3)
                    with col_info1:
                        st.metric("ì£¼ì œ", selected_roadmap["ì£¼ì œ"])
                    with col_info2:
                        st.metric("ë‚œì´ë„", selected_roadmap["ë‚œì´ë„"])
                    with col_info3:
                        st.metric("ìƒì„±ì‹œê°„", selected_roadmap["ìƒì„±ì‹œê°„"])
                    
                    # ë¡œë“œë§µ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¬ìƒì„±
                    if "ë°ì´í„°" in selected_roadmap:
                        st.subheader("ğŸ—ºï¸ ë¡œë“œë§µ ë¯¸ë¦¬ë³´ê¸°")
                        roadmap_data = selected_roadmap["ë°ì´í„°"]
                        
                        # ë§ˆì¸ë“œë§µ HTML ì¬ìƒì„±
                        mindmap_html = generate_mindmap_html(roadmap_data)
                        st.components.v1.html(mindmap_html, height=600, scrolling=True)
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        st.download_button(
                            label="ğŸ“¥ HTML íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=mindmap_html,
                            file_name=f"{selected_roadmap['ì£¼ì œ']}_roadmap.html",
                            mime="text/html",
                            key=f"download_viewed_{selected_roadmap['ì£¼ì œ']}"
                        )
        else:
            st.info("ìƒì„±ëœ ë¡œë“œë§µì´ ì—†ìŠµë‹ˆë‹¤. AI ë¡œë“œë§µ ìƒì„± íƒ­ì—ì„œ ë¡œë“œë§µì„ ìƒì„±í•´ë³´ì„¸ìš”.")

# HTML ì—…ë¡œë“œ/íŒŒì‹±
elif page == "HTML ì—…ë¡œë“œ/íŒŒì‹±":
    st.header("ğŸ“¤ HTML ì—…ë¡œë“œ/íŒŒì‹±")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        
        # Qdrant DB ì´ˆê¸°í™” ë²„íŠ¼
        col_init1, col_init2 = st.columns(2)
        with col_init1:
            if st.button("ğŸ—„ï¸ Qdrant Collection ì´ˆê¸°í™”", type="secondary"):
                try:
                    from react_roadmap_parser import QdrantRoadmapStore
                    from db_validation_logger import DatabaseValidationLogger
                    
                    validation_logger = DatabaseValidationLogger("validation_logs.db")
                    store = QdrantRoadmapStore(validation_logger=validation_logger)
                    store.initialize_collection(force_recreate=True)
                    st.success("Qdrant Collectionì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except ImportError:
                    st.error("Qdrant ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with col_init2:
            if st.button("ğŸ“Š Collection ìƒíƒœ í™•ì¸", type="secondary"):
                try:
                    from react_roadmap_parser import QdrantRoadmapStore
                    from db_validation_logger import DatabaseValidationLogger
                    
                    validation_logger = DatabaseValidationLogger("validation_logs.db")
                    store = QdrantRoadmapStore(validation_logger=validation_logger)
                    
                    # Collection ì •ë³´ í™•ì¸
                    collection_info = store.get_collection_info()
                    if collection_info:
                        st.success(f"âœ… Collection ìƒíƒœ: í™œì„±í™”")
                        col_info1, col_info2, col_info3 = st.columns(3)
                        with col_info1:
                            st.metric("í¬ì¸íŠ¸ ìˆ˜", collection_info.get('points_count', 'N/A'))
                        with col_info2:
                            st.metric("ë²¡í„° ìˆ˜", collection_info.get('vectors_count', 'N/A'))
                        with col_info3:
                            st.metric("ë²¡í„° í¬ê¸°", collection_info.get('config', {}).get('vector_size', 'N/A'))
                    else:
                        st.warning("âš ï¸ Collectionì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                except ImportError:
                    st.error("Qdrant ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        uploaded_file = st.file_uploader(
            "HTML íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['html', 'htm'],
            help="HTML ë§ˆì¸ë“œë§µ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ íŒŒì‹±í•©ë‹ˆë‹¤"
        )
        
        # ì¶”ê°€ íƒœê·¸ ì…ë ¥ë€
        custom_tags_input = st.text_input(
            "ì¶”ê°€ íƒœê·¸ ì…ë ¥ (ì½¤ë§ˆë¡œ êµ¬ë¶„)",
            value="",
            help="ì˜ˆ: project:myproj, version:1.0, customtag"
        )
        
        parsing_status = st.empty()
        nodes = None
        error_msg = None
        if uploaded_file is not None:
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            html_content = uploaded_file.read().decode('utf-8')
            filename = uploaded_file.name
            st.success(f"íŒŒì¼ '{filename}'ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            st.info(f"íŒŒì¼ í¬ê¸°: {len(html_content)} bytes")
            
            # íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€(ì¤‘ë³µ ë°©ì§€)
            if filename not in st.session_state.uploaded_filenames:
                st.session_state.uploaded_filenames.append(filename)

            # íŒŒì‹± ë° Qdrant ì ì¬ ë²„íŠ¼
            if st.button("ğŸ” íŒŒì‹± ë° Qdrant ì ì¬"):
                with st.spinner("íŒŒì‹± ë° Qdrant ì ì¬ ì¤‘..."):
                    try:
                        # ìƒˆë¡œìš´ íŒŒì‹± ë¡œì§ ì‚¬ìš©
                        roadmap_id = f"roadmap_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        
                        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                        metadata = extract_roadmap_metadata(html_content)
                        title = metadata.get("title", filename)
                        
                        # ì„¹ì…˜ë³„ ì²­í¬ ìƒì„±
                        st.info("ğŸ” HTML íŒŒì‹± ì‹œì‘...")
                        
                        # HTML ê¸°ë³¸ ì •ë³´ í‘œì‹œ
                        st.write(f"**HTML í¬ê¸°:** {len(html_content)} bytes")
                        
                        # HTML êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸°
                        soup = BeautifulSoup(html_content, 'html.parser')
                        title_elem = soup.find(['h1', 'title'])
                        if title_elem:
                            st.write(f"**ì œëª©:** {title_elem.get_text().strip()}")
                        
                        chunks = parse_html_sections(html_content, roadmap_id)
                        
                        st.write(f"**íŒŒì‹± ê²°ê³¼:** {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
                        
                        if not chunks:
                            st.warning("âš ï¸ íŒŒì‹±ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.write("**HTML êµ¬ì¡° ë¶„ì„:**")
                            
                            # HTML êµ¬ì¡° ë””ë²„ê¹…
                            soup = BeautifulSoup(html_content, 'html.parser')
                            
                            # ì£¼ìš” íƒœê·¸ ì°¾ê¸°
                            st.write("**ë°œê²¬ëœ ì£¼ìš” íƒœê·¸:**")
                            main_tags = soup.find_all(['div', 'section', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                            tag_info = []
                            for tag in main_tags[:10]:  # ìƒìœ„ 10ê°œë§Œ
                                classes = ' '.join(tag.get('class', []))
                                tag_info.append({
                                    "íƒœê·¸": tag.name,
                                    "í´ë˜ìŠ¤": classes,
                                    "í…ìŠ¤íŠ¸": tag.get_text().strip()[:50] + "..." if len(tag.get_text().strip()) > 50 else tag.get_text().strip()
                                })
                            st.dataframe(pd.DataFrame(tag_info), use_container_width=True)
                            
                            # í´ë˜ìŠ¤ë³„ ë¶„í¬
                            all_classes = []
                            for tag in soup.find_all():
                                all_classes.extend(tag.get('class', []))
                            
                            class_counts = {}
                            for cls in all_classes:
                                class_counts[cls] = class_counts.get(cls, 0) + 1
                            
                            if class_counts:
                                st.write("**í´ë˜ìŠ¤ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):**")
                                sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:10]
                                for cls, count in sorted_classes:
                                    st.write(f"â€¢ {cls}: {count}íšŒ")
                        else:
                            # íŒŒì¼ëª… íƒœê·¸ë¥¼ ëª¨ë“  ì²­í¬ì— ì¶”ê°€
                            for chunk in chunks:
                                chunk.collection_tags.append(f"filename:{filename}")
                                chunk.collection_tags.append(f"source:{filename}")
                                chunk.search_tags.append(f"filename:{filename}")
                                chunk.search_tags.append(f"source:{filename}")
                                # ì»¤ìŠ¤í…€ íƒœê·¸ë„ ì¶”ê°€
                                if custom_tags_input.strip():
                                    custom_tags = [t.strip() for t in custom_tags_input.split(",") if t.strip()]
                                    chunk.collection_tags.extend(custom_tags)
                                    chunk.search_tags.extend(custom_tags)
                            
                            # RoadmapDocument ìƒì„±
                            document = RoadmapDocument(
                                id=roadmap_id,
                                title=title,
                                original_html=html_content,
                                chunks=chunks,
                                metadata=metadata
                            )
                            
                            # ì„¸ì…˜ì— ì €ì¥
                            st.session_state.roadmap_documents[roadmap_id] = document
                            
                            parsing_status.success(f"âœ… íŒŒì‹± ê²°ê³¼: ì„±ê³µ! (ì²­í¬ ìˆ˜: {len(chunks)})")
                            
                            # íŒŒì‹± í†µê³„
                            st.write("**ğŸ“Š íŒŒì‹± í†µê³„:**")
                            type_counts = {}
                            category_counts = {}
                            for chunk in chunks:
                                chunk_type = chunk.metadata.get("type", "unknown")
                                type_counts[chunk_type] = type_counts.get(chunk_type, 0) + 1
                                
                                category = chunk.metadata.get("category", "unknown")
                                category_counts[category] = category_counts.get(category, 0) + 1
                            
                            col_stat1, col_stat2 = st.columns(2)
                            with col_stat1:
                                st.write("**íƒ€ì…ë³„ ë¶„í¬:**")
                                for chunk_type, count in type_counts.items():
                                    st.write(f"â€¢ {chunk_type}: {count}ê°œ")
                            
                            with col_stat2:
                                st.write("**ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:**")
                                for category, count in category_counts.items():
                                    st.write(f"â€¢ {category}: {count}ê°œ")
                            
                            # ë¯¸ë¦¬ë³´ê¸°
                            st.write("**íŒŒì‹±ëœ ì²­í¬ ì¼ë¶€ ë¯¸ë¦¬ë³´ê¸°:**")
                            preview_data = []
                            for chunk in chunks[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                                preview_data.append({
                                    "ID": chunk.id,
                                    "ì„¹ì…˜": chunk.metadata.get("section", "N/A"),
                                    "íƒ€ì…": chunk.metadata.get("type", "N/A"),
                                    "ë ˆë²¨": chunk.metadata.get("level", "N/A"),
                                    "ì¹´í…Œê³ ë¦¬": chunk.metadata.get("category", "N/A"),
                                    "í‚¤ì›Œë“œ": ", ".join(chunk.metadata.get("keywords", [])[:3]),
                                    "ë„êµ¬": ", ".join(chunk.metadata.get("tools", [])[:2]),
                                    "ìˆ˜ì§‘ íƒœê·¸": ", ".join(chunk.collection_tags[:3]),
                                    "ê²€ìƒ‰ íƒœê·¸": ", ".join(chunk.search_tags[:3]),
                                    "ë‚´ìš© ê¸¸ì´": len(chunk.content),
                                    "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°": chunk.content[:100] + "..." if len(chunk.content) > 100 else chunk.content
                                })
                            st.dataframe(pd.DataFrame(preview_data), use_container_width=True)
                            
                            # ìƒì„¸ ë¯¸ë¦¬ë³´ê¸° (ì²« ë²ˆì§¸ ì²­í¬)
                            if chunks:
                                st.write("**ì²« ë²ˆì§¸ ì²­í¬ ìƒì„¸ ë‚´ìš©:**")
                                first_chunk = chunks[0]
                                st.json({
                                    "id": first_chunk.id,
                                    "roadmap_id": first_chunk.roadmap_id,
                                    "metadata": {
                                        "section": first_chunk.metadata.get("section", "N/A"),
                                        "type": first_chunk.metadata.get("type", "N/A"),
                                        "level": first_chunk.metadata.get("level", "N/A"),
                                        "category": first_chunk.metadata.get("category", "N/A"),
                                        "keywords": first_chunk.metadata.get("keywords", []),
                                        "tools": first_chunk.metadata.get("tools", []),
                                        "resources": first_chunk.metadata.get("resources", []),
                                        "learning_objectives": first_chunk.metadata.get("learning_objectives", [])
                                    },
                                    "collection_tags": first_chunk.collection_tags,
                                    "search_tags": first_chunk.search_tags,
                                    "content_preview": first_chunk.content[:200] + "..." if len(first_chunk.content) > 200 else first_chunk.content
                                })
                            
                            # íƒœê·¸ ê´€ë¦¬ ì„¹ì…˜
                            st.write("---")
                            st.subheader("ğŸ·ï¸ íƒœê·¸ ê´€ë¦¬")
                            
                            # íƒœê·¸ í†µê³„
                            tag_stats = get_tag_statistics(chunks)
                            if tag_stats:
                                st.write("**ğŸ“Š í˜„ì¬ íƒœê·¸ í†µê³„:**")
                                col_tag1, col_tag2 = st.columns(2)
                                
                                with col_tag1:
                                    st.write("**ğŸ“¦ ìˆ˜ì§‘ íƒœê·¸ (ìƒìœ„ 10ê°œ):**")
                                    collection_sorted = sorted(tag_stats["collection_tags"].items(), key=lambda x: x[1], reverse=True)[:10]
                                    for tag, count in collection_sorted:
                                        st.write(f"â€¢ {tag}: {count}íšŒ")
                                
                                with col_tag2:
                                    st.write("**ğŸ” ê²€ìƒ‰ íƒœê·¸ (ìƒìœ„ 10ê°œ):**")
                                    search_sorted = sorted(tag_stats["search_tags"].items(), key=lambda x: x[1], reverse=True)[:10]
                                    for tag, count in search_sorted:
                                        st.write(f"â€¢ {tag}: {count}íšŒ")
                            
                            # ê°œë³„ ì²­í¬ íƒœê·¸ í¸ì§‘
                            st.write("**âœï¸ ì²­í¬ë³„ íƒœê·¸ í¸ì§‘:**")
                            
                            # ì²­í¬ ì„ íƒ
                            chunk_options = {f"{i+1}. {chunk.metadata.get('section', 'N/A')}": i for i, chunk in enumerate(chunks[:10])}
                            selected_chunk_key = st.selectbox("í¸ì§‘í•  ì²­í¬ ì„ íƒ:", list(chunk_options.keys()))
                            
                            if selected_chunk_key:
                                selected_chunk_idx = chunk_options[selected_chunk_key]
                                selected_chunk = chunks[selected_chunk_idx]
                                
                                # í˜„ì¬ íƒœê·¸ í‘œì‹œ
                                col_current1, col_current2 = st.columns(2)
                                with col_current1:
                                    st.write(f"**ğŸ“¦ ìˆ˜ì§‘ íƒœê·¸:** {', '.join(selected_chunk.collection_tags) if selected_chunk.collection_tags else 'ì—†ìŒ'}")
                                with col_current2:
                                    st.write(f"**ğŸ” ê²€ìƒ‰ íƒœê·¸:** {', '.join(selected_chunk.search_tags) if selected_chunk.search_tags else 'ì—†ìŒ'}")
                                
                                # íƒœê·¸ ì œì•ˆ
                                suggested_tags = suggest_tags_for_chunk(selected_chunk.content, selected_chunk.metadata)
                                if suggested_tags["collection_tags"] or suggested_tags["search_tags"]:
                                    col_suggest1, col_suggest2 = st.columns(2)
                                    with col_suggest1:
                                        if suggested_tags["collection_tags"]:
                                            st.write(f"**ğŸ“¦ ì œì•ˆ ìˆ˜ì§‘ íƒœê·¸:** {', '.join(suggested_tags['collection_tags'])}")
                                    with col_suggest2:
                                        if suggested_tags["search_tags"]:
                                            st.write(f"**ğŸ” ì œì•ˆ ê²€ìƒ‰ íƒœê·¸:** {', '.join(suggested_tags['search_tags'])}")
                                
                                # ì»¤ìŠ¤í…€ íƒœê·¸ ì…ë ¥
                                col_input1, col_input2 = st.columns(2)
                                with col_input1:
                                    collection_tags_input = st.text_input(
                                        "ì¶”ê°€í•  ìˆ˜ì§‘ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                        value="",
                                        help="ì˜ˆ: web-development, beginner, type-level"
                                    )
                                with col_input2:
                                    search_tags_input = st.text_input(
                                        "ì¶”ê°€í•  ê²€ìƒ‰ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                        value="",
                                        help="ì˜ˆ: react, javascript, frontend"
                                    )
                                
                                # íƒœê·¸ ì ìš© ë²„íŠ¼
                                if st.button("ğŸ·ï¸ íƒœê·¸ ì ìš©", key="apply_tags"):
                                    new_collection_tags = []
                                    new_search_tags = []
                                    
                                    if collection_tags_input.strip():
                                        new_collection_tags = [tag.strip().lower() for tag in collection_tags_input.split(",") if tag.strip()]
                                    
                                    if search_tags_input.strip():
                                        new_search_tags = [tag.strip().lower() for tag in search_tags_input.split(",") if tag.strip()]
                                    
                                    if new_collection_tags or new_search_tags:
                                        # ì²­í¬ ì—…ë°ì´íŠ¸
                                        updated_chunk = apply_tags_to_chunk(selected_chunk, new_collection_tags, new_search_tags)
                                        chunks[selected_chunk_idx] = updated_chunk
                                        
                                        # ë¬¸ì„œ ì—…ë°ì´íŠ¸
                                        document.chunks = chunks
                                        st.session_state.roadmap_documents[roadmap_id] = document
                                        
                                        st.success(f"âœ… íƒœê·¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤! (ìˆ˜ì§‘: {len(new_collection_tags)}ê°œ, ê²€ìƒ‰: {len(new_search_tags)}ê°œ)")
                                        
                                        # ì—…ë°ì´íŠ¸ëœ íƒœê·¸ í‘œì‹œ
                                        col_updated1, col_updated2 = st.columns(2)
                                        with col_updated1:
                                            st.write(f"**ğŸ“¦ ì—…ë°ì´íŠ¸ëœ ìˆ˜ì§‘ íƒœê·¸:** {', '.join(updated_chunk.collection_tags)}")
                                        with col_updated2:
                                            st.write(f"**ğŸ” ì—…ë°ì´íŠ¸ëœ ê²€ìƒ‰ íƒœê·¸:** {', '.join(updated_chunk.search_tags)}")
                            
                            # ì¼ê´„ íƒœê·¸ ì ìš©
                            st.write("**ğŸ“¦ ì¼ê´„ íƒœê·¸ ì ìš©:**")
                            col_bulk1, col_bulk2 = st.columns(2)
                            with col_bulk1:
                                bulk_collection_tags = st.text_input(
                                    "ëª¨ë“  ì²­í¬ì— ì ìš©í•  ìˆ˜ì§‘ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                    value="",
                                    help="ì˜ˆ: roadmap, learning"
                                )
                            with col_bulk2:
                                bulk_search_tags = st.text_input(
                                    "ëª¨ë“  ì²­í¬ì— ì ìš©í•  ê²€ìƒ‰ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                    value="",
                                    help="ì˜ˆ: tutorial, guide"
                                )
                            
                            if st.button("ğŸ“¦ ì¼ê´„ íƒœê·¸ ì ìš©", key="apply_bulk_tags"):
                                new_collection_tags = []
                                new_search_tags = []
                                
                                if bulk_collection_tags.strip():
                                    new_collection_tags = [tag.strip().lower() for tag in bulk_collection_tags.split(",") if tag.strip()]
                                
                                if bulk_search_tags.strip():
                                    new_search_tags = [tag.strip().lower() for tag in bulk_search_tags.split(",") if tag.strip()]
                                
                                if new_collection_tags or new_search_tags:
                                    # ëª¨ë“  ì²­í¬ì— íƒœê·¸ ì ìš©
                                    updated_chunks = []
                                    for chunk in chunks:
                                        updated_chunk = apply_tags_to_chunk(chunk, new_collection_tags, new_search_tags)
                                        updated_chunks.append(updated_chunk)
                                    
                                    # ë¬¸ì„œ ì—…ë°ì´íŠ¸
                                    document.chunks = updated_chunks
                                    st.session_state.roadmap_documents[roadmap_id] = document
                                    
                                    st.success(f"âœ… ì¼ê´„ íƒœê·¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤! ({len(chunks)}ê°œ ì²­í¬)")
                            
                            # íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰
                            st.write("**ğŸ” íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰:**")
                            col_search1, col_search2 = st.columns(2)
                            with col_search1:
                                search_collection_tags = st.text_input(
                                    "ê²€ìƒ‰í•  ìˆ˜ì§‘ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                    value="",
                                    help="ì˜ˆ: beginner, web-development"
                                )
                            with col_search2:
                                search_search_tags = st.text_input(
                                    "ê²€ìƒ‰í•  ê²€ìƒ‰ íƒœê·¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„):",
                                    value="",
                                    help="ì˜ˆ: react, javascript"
                                )
                            
                            if st.button("ğŸ” íƒœê·¸ ê²€ìƒ‰", key="search_by_tags"):
                                matched_chunks = chunks
                                
                                # ìˆ˜ì§‘ íƒœê·¸ ê²€ìƒ‰
                                if search_collection_tags.strip():
                                    collection_search_tags = [tag.strip().lower() for tag in search_collection_tags.split(",") if tag.strip()]
                                    matched_chunks = search_chunks_by_tags(matched_chunks, collection_search_tags, "collection")
                                
                                # ê²€ìƒ‰ íƒœê·¸ ê²€ìƒ‰
                                if search_search_tags.strip():
                                    search_search_tag_list = [tag.strip().lower() for tag in search_search_tags.split(",") if tag.strip()]
                                    matched_chunks = search_chunks_by_tags(matched_chunks, search_search_tag_list, "search")
                                
                                st.write(f"**ê²€ìƒ‰ ê²°ê³¼:** {len(matched_chunks)}ê°œ ì²­í¬ ë°œê²¬")
                                
                                if matched_chunks:
                                    search_results = []
                                    for i, chunk in enumerate(matched_chunks[:5]):
                                        search_results.append({
                                            "ìˆœì„œ": i + 1,
                                            "ì„¹ì…˜": chunk.metadata.get("section", "N/A"),
                                            "íƒ€ì…": chunk.metadata.get("type", "N/A"),
                                            "ìˆ˜ì§‘ íƒœê·¸": ", ".join(chunk.collection_tags[:3]),
                                            "ê²€ìƒ‰ íƒœê·¸": ", ".join(chunk.search_tags[:3]),
                                            "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°": chunk.content[:100] + "..." if len(chunk.content) > 100 else chunk.content
                                        })
                                    st.dataframe(pd.DataFrame(search_results), use_container_width=True)
                                else:
                                    st.info("ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                                                # ê¸°ì¡´ íŒŒì‹± ë¡œì§ë„ ìœ ì§€ (í˜¸í™˜ì„±)
                        try:
                            from react_roadmap_parser import ReactRoadmapParser, QdrantRoadmapStore
                            from db_validation_logger import DatabaseValidationLogger
                            validation_logger = DatabaseValidationLogger("validation_logs.db")
                            parser = ReactRoadmapParser(html_content, validation_logger)
                            nodes = parser.parse()
                            
                            # íŒŒì¼ëª… íƒœê¹…
                            for n in nodes:
                                if hasattr(n, 'tags') and isinstance(n.tags, list):
                                    n.tags.append(f"source:{filename}")
                                    n.tags.append(f"filename:{filename}")
                                if hasattr(n, 'links') and isinstance(n.links, list):
                                    for link in n.links:
                                        if isinstance(link, dict):
                                            link['source'] = filename
                            
                            # Qdrant ì ì¬
                            store = QdrantRoadmapStore(validation_logger=validation_logger)
                            store.initialize_collection(force_recreate=False)
                            store.store_nodes(nodes)
                            st.success("Qdrant DBì— ì ì¬ ì™„ë£Œ!")
                            
                            # ë””ë¹„ ì ì¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                            st.write("**ğŸ“Š Qdrant DB ì ì¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**")
                            
                            # Collection ì •ë³´ í™•ì¸
                            collection_info = store.get_collection_info()
                            if collection_info:
                                col_db1, col_db2, col_db3 = st.columns(3)
                                with col_db1:
                                    st.metric("ì €ì¥ëœ í¬ì¸íŠ¸", collection_info.get('points_count', 0))
                                with col_db2:
                                    st.metric("ë²¡í„° ìˆ˜", collection_info.get('vectors_count', 0))
                                with col_db3:
                                    st.metric("Collection ìƒíƒœ", "í™œì„±í™”")
                            
                            # ì €ì¥ëœ ë…¸ë“œ ìƒ˜í”Œ ì¡°íšŒ
                            try:
                                # ì¹´í…Œê³ ë¦¬ë³„ ë…¸ë“œ ìˆ˜ ì¡°íšŒ
                                categories = ['beginner', 'intermediate', 'advanced', 'community']
                                category_counts = {}
                                for category in categories:
                                    category_nodes = store.get_nodes_by_category(category)
                                    category_counts[category] = len(category_nodes)
                                
                                st.write("**ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë…¸ë“œ ë¶„í¬:**")
                                category_df = pd.DataFrame([
                                    {"ì¹´í…Œê³ ë¦¬": cat, "ë…¸ë“œ ìˆ˜": count}
                                    for cat, count in category_counts.items()
                                ])
                                st.dataframe(category_df, use_container_width=True)
                                
                                # ìµœê·¼ ì €ì¥ëœ ë…¸ë“œ ìƒ˜í”Œ ì¡°íšŒ
                                st.write("**ğŸ” ì €ì¥ëœ ë…¸ë“œ ìƒ˜í”Œ:**")
                                sample_nodes = []
                                for category in categories:
                                    nodes = store.get_nodes_by_category(category)
                                    if nodes:
                                        sample_nodes.extend(nodes[:2])  # ì¹´í…Œê³ ë¦¬ë‹¹ 2ê°œì”©
                                        if len(sample_nodes) >= 6:  # ìµœëŒ€ 6ê°œ
                                            break
                                
                                if sample_nodes:
                                    node_preview_data = []
                                    for i, node_data in enumerate(sample_nodes[:6]):
                                        node_preview_data.append({
                                            "ìˆœì„œ": i + 1,
                                            "ì œëª©": node_data.get('title', 'N/A')[:30] + "..." if len(node_data.get('title', '')) > 30 else node_data.get('title', 'N/A'),
                                            "ì¹´í…Œê³ ë¦¬": node_data.get('category', 'N/A'),
                                            "íƒ€ì…": node_data.get('node_type', 'N/A'),
                                            "íƒœê·¸ ìˆ˜": len(node_data.get('tags', [])),
                                            "ë§í¬ ìˆ˜": len(node_data.get('links', []))
                                        })
                                    st.dataframe(pd.DataFrame(node_preview_data), use_container_width=True)
                                    
                                    # ì²« ë²ˆì§¸ ë…¸ë“œ ìƒì„¸ ì •ë³´
                                    if sample_nodes:
                                        st.write("**ğŸ“‹ ì²« ë²ˆì§¸ ë…¸ë“œ ìƒì„¸ ì •ë³´:**")
                                        first_node = sample_nodes[0]
                                        st.json({
                                            "id": first_node.get('id', 'N/A'),
                                            "title": first_node.get('title', 'N/A'),
                                            "category": first_node.get('category', 'N/A'),
                                            "node_type": first_node.get('node_type', 'N/A'),
                                            "depth": first_node.get('depth', 'N/A'),
                                            "tags": first_node.get('tags', []),
                                            "links": first_node.get('links', [])
                                        })
                                else:
                                    st.info("ì €ì¥ëœ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                                    
                            except Exception as e:
                                st.warning(f"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                
                        except ImportError:
                            st.warning("ê¸°ì¡´ íŒŒì‹± ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒˆë¡œìš´ íŒŒì‹± ë°©ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                        
                    except Exception as e:
                        error_msg = str(e)
                        parsing_status.error(f"íŒŒì‹± ê²°ê³¼: ì‹¤íŒ¨ - {error_msg}")
        else:
            parsing_status.info("HTML íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  íŒŒì‹±í•´ì£¼ì„¸ìš”")
    
    with col2:
        st.subheader("ğŸ” íŒŒì‹± ê²°ê³¼")
        
        if parsing_status.empty():
            st.info("HTML íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  íŒŒì‹±í•´ì£¼ì„¸ìš”")
        elif parsing_status.success:
            # íŒŒì‹± í†µê³„
            if st.session_state.roadmap_documents:
                latest_doc = list(st.session_state.roadmap_documents.values())[-1]
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("ì²­í¬ ìˆ˜", len(latest_doc.chunks))
                with col_b:
                    st.metric("í‚¤ì›Œë“œ ìˆ˜", len(latest_doc.metadata.get("tags", [])))
                with col_c:
                    st.metric("ë¬¸ì„œ ì œëª©", latest_doc.title[:20] + "..." if len(latest_doc.title) > 20 else latest_doc.title)
                
                # ë°œê²¬ëœ í‚¤ì›Œë“œë“¤
                st.write("**ë°œê²¬ëœ í‚¤ì›Œë“œ:**")
                tags = latest_doc.metadata.get("tags", [])
                if tags:
                    tag_cols = st.columns(3)
                    for i, tag in enumerate(tags[:9]):  # ìƒìœ„ 9ê°œë§Œ
                        col_idx = i % 3
                        tag_cols[col_idx].write(f"â€¢ {tag}")
                
                # êµ¬ì¡° ì •ë³´
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.write(f"**ë‚œì´ë„:** {latest_doc.metadata.get('difficulty', 'unknown')}")
                with col_info2:
                    st.write(f"**ì¹´í…Œê³ ë¦¬:** {latest_doc.metadata.get('category', 'programming')}")
                
                # ì²­í¬ë³„ ìƒì„¸ ì •ë³´
                st.write("**ì²­í¬ë³„ ìƒì„¸ ì •ë³´:**")
                chunk_details = []
                for i, chunk in enumerate(latest_doc.chunks[:10]):  # ìƒìœ„ 10ê°œë§Œ
                    chunk_details.append({
                        "ìˆœì„œ": i + 1,
                        "ID": chunk.id,
                        "ì„¹ì…˜": chunk.metadata.get("section", "N/A"),
                        "íƒ€ì…": chunk.metadata.get("type", "N/A"),
                        "ë ˆë²¨": chunk.metadata.get("level", "N/A"),
                        "ì¹´í…Œê³ ë¦¬": chunk.metadata.get("category", "N/A"),
                        "í‚¤ì›Œë“œ ìˆ˜": len(chunk.metadata.get("keywords", [])),
                        "ë„êµ¬ ìˆ˜": len(chunk.metadata.get("tools", [])),
                        "ë¦¬ì†ŒìŠ¤ ìˆ˜": len(chunk.metadata.get("resources", [])),
                        "í•™ìŠµëª©í‘œ ìˆ˜": len(chunk.metadata.get("learning_objectives", [])),
                        "ìˆ˜ì§‘ íƒœê·¸": ", ".join(chunk.collection_tags[:3]),
                        "ê²€ìƒ‰ íƒœê·¸": ", ".join(chunk.search_tags[:3]),
                        "ë‚´ìš© ê¸¸ì´": len(chunk.content),
                        "HTML ê¸¸ì´": len(chunk.html_fragment)
                    })
                st.dataframe(pd.DataFrame(chunk_details), use_container_width=True)
                
                # íƒœê·¸ í†µê³„
                tag_stats = get_tag_statistics(latest_doc.chunks)
                if tag_stats:
                    st.write("**ğŸ·ï¸ íƒœê·¸ í†µê³„:**")
                    col_tag_stat1, col_tag_stat2 = st.columns(2)
                    
                    with col_tag_stat1:
                        st.write("**ğŸ“¦ ìˆ˜ì§‘ íƒœê·¸ (ìƒìœ„ 10ê°œ):**")
                        collection_sorted = sorted(tag_stats["collection_tags"].items(), key=lambda x: x[1], reverse=True)[:10]
                        for tag, count in collection_sorted:
                            st.write(f"â€¢ {tag}: {count}íšŒ")
                    
                    with col_tag_stat2:
                        st.write("**ğŸ” ê²€ìƒ‰ íƒœê·¸ (ìƒìœ„ 10ê°œ):**")
                        search_sorted = sorted(tag_stats["search_tags"].items(), key=lambda x: x[1], reverse=True)[:10]
                        for tag, count in search_sorted:
                            st.write(f"â€¢ {tag}: {count}íšŒ")
                
                # êµ¬ì¡°í™”ëœ ì •ë³´ ìš”ì•½
                st.write("**ğŸ—ï¸ êµ¬ì¡°í™”ëœ ì •ë³´ ìš”ì•½:**")
                col_sum1, col_sum2 = st.columns(2)
                
                with col_sum1:
                    # íƒ€ì…ë³„ ë¶„í¬
                    type_counts = {}
                    for chunk in latest_doc.chunks:
                        chunk_type = chunk.metadata.get("type", "unknown")
                        type_counts[chunk_type] = type_counts.get(chunk_type, 0) + 1
                    
                    st.write("**íƒ€ì…ë³„ ë¶„í¬:**")
                    for chunk_type, count in type_counts.items():
                        st.write(f"â€¢ {chunk_type}: {count}ê°œ")
                    
                    # ë„êµ¬ë³„ ë¶„í¬
                    all_tools = []
                    for chunk in latest_doc.chunks:
                        all_tools.extend(chunk.metadata.get("tools", []))
                    
                    tool_counts = {}
                    for tool in all_tools:
                        tool_counts[tool] = tool_counts.get(tool, 0) + 1
                    
                    if tool_counts:
                        st.write("**ğŸ”§ ë°œê²¬ëœ ë„êµ¬:**")
                        for tool, count in sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
                            st.write(f"â€¢ {tool}: {count}íšŒ")
                
                with col_sum2:
                    # ë¦¬ì†ŒìŠ¤ë³„ ë¶„í¬
                    all_resources = []
                    for chunk in latest_doc.chunks:
                        all_resources.extend(chunk.metadata.get("resources", []))
                    
                    resource_types = {}
                    for resource in all_resources:
                        resource_type = resource.get("type", "unknown")
                        resource_types[resource_type] = resource_types.get(resource_type, 0) + 1
                    
                    if resource_types:
                        st.write("**ğŸ“š ë¦¬ì†ŒìŠ¤ íƒ€ì…ë³„ ë¶„í¬:**")
                        for res_type, count in sorted(resource_types.items(), key=lambda x: x[1], reverse=True):
                            st.write(f"â€¢ {res_type}: {count}ê°œ")
                    
                    # í•™ìŠµ ëª©í‘œ ìš”ì•½
                    all_objectives = []
                    for chunk in latest_doc.chunks:
                        all_objectives.extend(chunk.metadata.get("learning_objectives", []))
                    
                    if all_objectives:
                        st.write("**ğŸ¯ í•™ìŠµ ëª©í‘œ (ì¼ë¶€):**")
                        for obj in all_objectives[:3]:
                            st.write(f"â€¢ {obj[:50]}{'...' if len(obj) > 50 else ''}")
                
                # ì €ì¥ ë²„íŠ¼
                if st.button("ğŸ’¾ Qdrant ì €ì¥", key="save_parsed"):
                    st.success("íŒŒì‹±ëœ ë°ì´í„°ê°€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif parsing_status.data:
                # ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„±
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("ë…¸ë“œ ìˆ˜", parsing_status.data["nodes"])
                with col_b:
                    st.metric("ë§í¬ ìˆ˜", parsing_status.data["links"])
                
                # ë°œê²¬ëœ ì£¼ì œë“¤
                st.write("**ë°œê²¬ëœ ì£¼ì œ:**")
                for topic in parsing_status.data["topics"]:
                    st.write(f"â€¢ {topic}")
                
                # êµ¬ì¡° ì •ë³´
                st.write(f"**êµ¬ì¡° ìœ í˜•:** {parsing_status.data['structure']}")
                
                # ì €ì¥ ë²„íŠ¼
                if st.button("ğŸ’¾ Qdrant ì €ì¥", key="save_parsed_old"):
                    st.success("íŒŒì‹±ëœ ë°ì´í„°ê°€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        elif parsing_status.error:
            st.error(f"íŒŒì‹± ê²°ê³¼: ì‹¤íŒ¨ - {parsing_status.data}")

# DB â†’ HTML ì¬ìƒì„±
elif page == "DB â†’ HTML ì¬ìƒì„±":
    st.header("ğŸ”„ DB â†’ HTML ì¬ìƒì„±")
    
    # ì—…ë¡œë“œëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
    if st.session_state.get('uploaded_filenames'):
        st.info("ì—…ë¡œë“œëœ íŒŒì¼ëª…: " + ", ".join(st.session_state.uploaded_filenames))
    
    # ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
    if st.session_state.roadmap_documents:
        st.subheader("ğŸ“š ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡")
        doc_list = []
        for doc_id, doc in st.session_state.roadmap_documents.items():
            doc_list.append({
                "ID": doc_id,
                "ì œëª©": doc.title,
                "ì²­í¬ ìˆ˜": len(doc.chunks),
                "íƒœê·¸": ", ".join(doc.metadata.get("tags", [])[:3]),
                "ë‚œì´ë„": doc.metadata.get("difficulty", "unknown")
            })
        st.dataframe(pd.DataFrame(doc_list))
    
    # ê²€ìƒ‰ ë° ì¬ìƒì„± í¼
    with st.form("search_form"):
        col1, col2 = st.columns(2)
        with col1:
            # íŒŒì¼ëª… ì„ íƒ ë“œë¡­ë‹¤ìš´ ì¶”ê°€
            if st.session_state.get('uploaded_filenames'):
                st.write("**ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰:**")
                selected_filename = st.selectbox(
                    "íŒŒì¼ëª… ì„ íƒ:",
                    options=["ì§ì ‘ ì…ë ¥"] + st.session_state.uploaded_filenames,
                    help="íŒŒì¼ëª…ì„ ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ ê²€ìƒ‰ì–´ê°€ ì…ë ¥ë©ë‹ˆë‹¤"
                )
                
                if selected_filename != "ì§ì ‘ ì…ë ¥":
                    # ì„ íƒëœ íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰ì–´ ìë™ ì„¤ì •
                    search_query = f"filename:{selected_filename}"
                    subject = st.text_input("ì£¼ì œ ê²€ìƒ‰", value=search_query, placeholder="ê²€ìƒ‰í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                else:
                    subject = st.text_input("ì£¼ì œ ê²€ìƒ‰", placeholder="ê²€ìƒ‰í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: filename:react_roadmap.html)")
            else:
                subject = st.text_input("ì£¼ì œ ê²€ìƒ‰", placeholder="ê²€ìƒ‰í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: filename:react_roadmap.html)")
            
            level = st.selectbox("ë‚œì´ë„ í•„í„°", ["all", "beginner", "intermediate", "advanced", "community"])
        with col2:
            focus_areas = st.text_input("ì¤‘ì ë¶„ì•¼ (ì½¤ë§ˆë¡œ êµ¬ë¶„)", value="")
            output_format = st.selectbox("ì¶œë ¥ í˜•ì‹", ["html", "json", "markdown"], index=0)
        
        similarity_threshold = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.0, 1.0, 0.1, 0.1)
        
        # íŒŒì¼ëª… ê²€ìƒ‰ ë„ì›€ë§
        st.info("ğŸ’¡ **íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ë ¤ë©´:** `filename:íŒŒì¼ëª….html` ë˜ëŠ” `source:íŒŒì¼ëª….html` í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”")
        
        regenerate = st.form_submit_button("ğŸ”„ HTML ì¬ìƒì„±", type="primary")
    
    # í¼ ë°–ì—ì„œ ê²°ê³¼ ì²˜ë¦¬ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    if regenerate:
        with st.spinner("ë¡œë“œë§µ ìƒì„± ì¤‘..."):
            if st.session_state.roadmap_documents:
                # ìƒˆë¡œìš´ ê²€ìƒ‰ ê¸°ë°˜ ì¬ìƒì„±
                query = subject or "React"
                # ê¸°ì¡´: generated_html = search_and_generate_html(query, st.session_state.roadmap_documents, similarity_threshold)
                # 1. ì²­í¬ ê²€ìƒ‰
                matched_chunks = []
                for doc in st.session_state.roadmap_documents.values():
                    for chunk in doc.chunks:
                        # íŒŒì¼ëª…/íƒœê·¸/í…ìŠ¤íŠ¸ ê²€ìƒ‰
                        if query.lower() in chunk.content.lower() or any(query.lower() in tag.lower() for tag in chunk.collection_tags + chunk.search_tags):
                            matched_chunks.append(chunk)
                if not matched_chunks:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                # 2. ê³„ì¸µì  êµ¬ì¡°ë¡œ ë³€í™˜
                roadmap_data = convert_chunks_to_roadmap_data(matched_chunks, main_topic=query)
                # 3. ë§ˆì¸ë“œë§µ HTML ìƒì„±
                generated_html = generate_mindmap_html(roadmap_data)
                # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.generated_result = {
                    "query": query,
                    "html_content": generated_html,
                    "output_format": output_format,
                    "generated_at": datetime.now().isoformat()
                }
                st.success(f"ë¡œë“œë§µ ìƒì„± ì™„ë£Œ! ê²€ìƒ‰ì–´: '{query}'")
                if output_format == "html":
                    st.components.v1.html(generated_html, height=600, scrolling=True)
                elif output_format == "json":
                    st.json(roadmap_data)
                elif output_format == "markdown":
                    markdown_content = f"# {query} í•™ìŠµ ë¡œë“œë§µ\n\n" + str(roadmap_data)
                    st.code(markdown_content, language="markdown")
            else:
                # ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„±
                try:
                    from roadmap_generator import RoadmapGenerator, RoadmapGenerationRequest
                    from react_roadmap_parser import QdrantRoadmapStore
                    
                    store = QdrantRoadmapStore()
                    generator = RoadmapGenerator(store)
                    request = RoadmapGenerationRequest(
                        subject=subject or "React",
                        level=level,
                        focus_areas=[x.strip() for x in focus_areas.split(",") if x.strip()],
                        output_format=output_format,
                        save_to_file=False
                    )
                    result = generator.generate_roadmap(request)
                    st.success(f"ë¡œë“œë§µ ìƒì„± ì™„ë£Œ! ë…¸ë“œ ìˆ˜: {result['metadata'].get('node_count', 0)}")
                    
                    if output_format == "html":
                        st.components.v1.html(result["content"], height=600, scrolling=True)
                    elif output_format == "json":
                        st.json(result["content"])
                    elif output_format == "markdown":
                        st.code(result["content"], language="markdown")
                except ImportError:
                    st.error("ë¡œë“œë§µ ìƒì„± ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ (í¼ ë°–ì—ì„œ í‘œì‹œ)
    if hasattr(st.session_state, 'generated_result'):
        result = st.session_state.generated_result
        query = result["query"]
        html_content = result["html_content"]
        output_format = result["output_format"]
        
        st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
        
        if output_format == "html":
            st.download_button(
                "â¬‡ï¸ HTML ë‹¤ìš´ë¡œë“œ", 
                data=html_content, 
                file_name=f"{query}_roadmap.html", 
                key=f"download_search_html_{query}"
            )
        elif output_format == "json":
            result_data = {
                "query": query,
                "generated_at": result["generated_at"],
                "html_content": html_content,
                "source_documents": list(st.session_state.roadmap_documents.keys()) if st.session_state.roadmap_documents else []
            }
            st.download_button(
                "â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ", 
                data=json.dumps(result_data, indent=2), 
                file_name=f"{query}_roadmap.json", 
                key=f"download_search_json_{query}"
            )
        elif output_format == "markdown":
            markdown_content = f"# {query} í•™ìŠµ ë¡œë“œë§µ\n\n"
            markdown_content += f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            markdown_content += "## ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ í•™ìŠµ ê²½ë¡œ\n\n"
            markdown_content += "ì´ ë¡œë“œë§µì€ ê²€ìƒ‰ì–´ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì¬êµ¬ì„±í•œ ê²ƒì…ë‹ˆë‹¤.\n\n"
            
            st.download_button(
                "â¬‡ï¸ Markdown ë‹¤ìš´ë¡œë“œ", 
                data=markdown_content, 
                file_name=f"{query}_roadmap.md", 
                key=f"download_search_md_{query}"
            )

# AI ë°°ì¹˜ ê²€ì¦/ë³´ì™„
elif page == "AI ë°°ì¹˜ ê²€ì¦/ë³´ì™„":
    st.header("âš¡ AI ë°°ì¹˜ ê²€ì¦/ë³´ì™„")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ” ë°°ì¹˜ ì‹¤í–‰")
        chatgpt_model = st.session_state.get("chatgpt_model", "gpt-3.5-turbo")
        openai_api_key = st.session_state.get("openai_api_key", "")
        if st.button("ğŸ” ê²€ì¦/ë³´ì™„ ë°°ì¹˜ ì‹¤í–‰", type="primary"):
            if not openai_api_key:
                st.error("âŒ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                st.info("ì‹¤í–‰ ë¡œê·¸ê°€ ì•„ë˜ì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
                log_placeholder = st.empty()
                progress_placeholder = st.empty()
                log_lines = []
                q = queue.Queue()
                def run_and_stream():
                    process = Popen([
                        'python', 'run_batch.py', '--once',
                        '--model', chatgpt_model,
                        '--api_key', openai_api_key
                    ], stdout=PIPE, stderr=STDOUT, text=True, bufsize=1)
                    for line in process.stdout:
                        q.put(line)
                    process.stdout.close()
                    process.wait()
                    q.put(None)
                t = threading.Thread(target=run_and_stream)
                t.start()
                while True:
                    try:
                        line = q.get(timeout=0.1)
                    except queue.Empty:
                        time.sleep(0.1)
                        continue
                    if line is None:
                        break
                    log_lines.append(line)
                    log_placeholder.code(''.join(log_lines), language='bash')
                    progress_placeholder.progress(min(100, len(log_lines) % 100))
                progress_placeholder.empty()
                st.success("ì‹¤í–‰ ì™„ë£Œ!")
                st.text_area("ì „ì²´ STDOUT ë¡œê·¸", ''.join(log_lines), height=200)
    with col2:
        st.subheader("ğŸ“Š ê²€ì¦/ë³´ì™„ ê²°ê³¼")
        st.info("ë°°ì¹˜ ì‘ì—…ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤")

# ë³€ê²½ ë¡œê·¸/ì´ë ¥
elif page == "ë³€ê²½ ë¡œê·¸/ì´ë ¥":
    st.header("ğŸ“‹ ë³€ê²½ ë¡œê·¸/ì´ë ¥")
    
    # í•„í„°ë§ ì˜µì…˜
    col1, col2, col3 = st.columns(3)
    with col1:
        search_term = st.text_input("ğŸ” ê²€ìƒ‰ì–´", placeholder="ë¡œê·¸ ê²€ìƒ‰")
    with col2:
        date_filter = st.date_input("ğŸ“… ë‚ ì§œ í•„í„°")
    with col3:
        status_filter = st.selectbox("ìƒíƒœ í•„í„°", ["ì „ì²´", "ì™„ë£Œ", "ì§„í–‰ì¤‘", "ì‹¤íŒ¨"])
    
    # ë¡œê·¸ í…Œì´ë¸”
    st.subheader("ğŸ“Š ë³€ê²½ ì´ë ¥")
    
    logs_df = pd.DataFrame(st.session_state.logs)
    
    # í•„í„°ë§ ì ìš©
    if search_term:
        logs_df = logs_df[logs_df['ë³€ê²½ë‚´ìš©'].str.contains(search_term, case=False, na=False)]
    
    if status_filter != "ì „ì²´":
        logs_df = logs_df[logs_df['ìƒíƒœ'] == status_filter]
    
    # ìƒíƒœë³„ ìƒ‰ìƒ ì ìš©
    def style_status(val):
        if val == "ì™„ë£Œ":
            return "background-color: #dcfce7; color: #166534"
        elif val == "ì§„í–‰ì¤‘":
            return "background-color: #fef3c7; color: #92400e"
        elif val == "ì‹¤íŒ¨":
            return "background-color: #fee2e2; color: #991b1b"
        return ""
    
    styled_df = logs_df.style.applymap(style_status, subset=['ìƒíƒœ'])
    st.dataframe(styled_df, use_container_width=True)
    
    # í†µê³„ ì •ë³´
    st.subheader("ğŸ“ˆ ë¡œê·¸ í†µê³„")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_logs = len(logs_df)
        st.metric("ì „ì²´ ë¡œê·¸", total_logs)
    
    with col2:
        completed = len(logs_df[logs_df['ìƒíƒœ'] == 'ì™„ë£Œ'])
        st.metric("ì™„ë£Œ", completed)
    
    with col3:
        failed = len(logs_df[logs_df['ìƒíƒœ'] == 'ì‹¤íŒ¨'])
        st.metric("ì‹¤íŒ¨", failed)
    
    # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
    if st.button("â¬‡ï¸ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ"):
        csv = logs_df.to_csv(index=False)
        st.download_button(
            label="CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"change_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="download_change_logs_csv"
        )
    
    # ì‹œê°„ë³„ ë³€ê²½ ì¶”ì´
    st.subheader("ğŸ“Š ì‹œê°„ë³„ ë³€ê²½ ì¶”ì´")
    
    # ì‹œê°„ë³„ ë°ì´í„° ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
    time_data = pd.DataFrame({
        "ì‹œê°„": pd.date_range(start='2024-01-01', periods=30, freq='D'),
        "ë³€ê²½ìˆ˜": [2, 3, 1, 4, 2, 3, 5, 2, 1, 3, 4, 2, 6, 3, 2, 1, 4, 3, 2, 5, 3, 2, 1, 4, 3, 2, 5, 3, 2, 1]
    })
    
    fig = px.line(time_data, x="ì‹œê°„", y="ë³€ê²½ìˆ˜", title="ì¼ë³„ ë³€ê²½ ë¡œê·¸ ì¶”ì´")
    st.plotly_chart(fig, use_container_width=True)

# í‘¸í„°
st.markdown("---")
st.markdown("*ğŸ—ºï¸ í•™ìŠµë¡œë“œë§µ ì‹œìŠ¤í…œ v1.0 - AI ê¸°ë°˜ ê°œì¸í™” í•™ìŠµ ê²½ë¡œ ìƒì„±*")

def convert_chunks_to_roadmap_data(chunks: List[RoadmapChunk], main_topic: str = "ë¡œë“œë§µ") -> Dict[str, Any]:
    """
    DBì—ì„œ ì½ì€ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ generate_mindmap_htmlì—ì„œ ìš”êµ¬í•˜ëŠ” ê³„ì¸µì  dict êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    prerequisites = []
    phases = []
    resources = []
    phase_dict = {}
    for chunk in chunks:
        if chunk.metadata.get("type") in ["prerequisite", "requirement"] or "ì‚¬ì „" in chunk.metadata.get("section", ""):
            prerequisites.append(chunk.content)
        if chunk.metadata.get("resources"):
            for res in chunk.metadata["resources"]:
                if isinstance(res, dict):
                    resources.append(res.get("title") or res.get("url") or str(res))
                else:
                    resources.append(str(res))
        level = chunk.metadata.get("level", 1)
        phase_key = f"{level}"
        if phase_key not in phase_dict:
            phase_dict[phase_key] = {
                "title": chunk.metadata.get("section", f"ë‹¨ê³„ {level}"),
                "duration": "",
                "topics": []
            }
        topic = {
            "title": chunk.metadata.get("section", ""),
            "description": chunk.content,
            "learning_links": []
        }
        if chunk.metadata.get("resources"):
            for res in chunk.metadata["resources"]:
                if isinstance(res, dict) and res.get("url"):
                    topic["learning_links"].append({
                        "title": res.get("title", res.get("url")),
                        "url": res.get("url")
                    })
        phase_dict[phase_key]["topics"].append(topic)
    phases = [phase_dict[k] for k in sorted(phase_dict.keys(), key=lambda x: int(x) if x.isdigit() else x)]
    return {
        "main_topic": main_topic,
        "prerequisites": prerequisites,
        "phases": phases,
        "resources": resources
    }
